{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load an image and pass it to a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, img_as_float, img_as_ubyte\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "#import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "#significant input from https://amaarora.github.io/2020/09/13/unet.html and Pytorch documentation examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes = 15\n",
    "#def name_to_hrs (r): return float(round(float(os.path.basename(r)[0:-4].split(\"_\")[1][1:])*(minutes/60)+5,2))\n",
    "def name_to_hrs (r): return float(round(float(os.path.basename(r)[0:-4].split(\"_\")[1][1:])*(minutes/60)+5,2))\n",
    "time = name_to_hrs('D:/pytorch/data/2D_FishAge_pytorch/images/S000_t000028_V000_R0005_X000_Y000_C02_I0_D0_P00344_MP.tif')\n",
    "device = 'cuda'\n",
    "img_train_paths = glob('D:/pytorch/data/2D_FishAge_pytorch/images/*.tif')\n",
    "img_test_paths = glob('D:/pytorch/data/2D_FishAge_pytorch/testimages/*.tif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time\n",
    "#model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=1, out_channels=1, init_features=8, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for a standard unet block that takes in in_ch and results in out_ch\n",
    "# 3x3 conv and no padding currently\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3,1,1)\n",
    "        self.norm1 = nn.BatchNorm2d(out_ch, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.relu  =nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3,1,1)\n",
    "        self.norm2 = nn.BatchNorm2d(out_ch, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.norm2(self.conv2(self.relu(self.norm1(self.conv1(x))))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, chs = (1,64,128,256,512,1024)):\n",
    "        super().__init__()\n",
    "        self.enc_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)])\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = []\n",
    "        for block in self.enc_blocks:\n",
    "            x=block(x)\n",
    "            features.append(x)\n",
    "            x=self.pool(x)\n",
    "        return features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, chs=(1024,512,256,128,64)):\n",
    "        super().__init__()\n",
    "        self.chs = chs\n",
    "        self.upconvs = nn.ModuleList([nn.ConvTranspose2d(chs[i], chs[i+1], 2,2) for i in range(len(chs)-1)])\n",
    "        self.dec_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)])\n",
    "\n",
    "    def forward(self, x, encoder_features):\n",
    "        for i in range(len(self.chs)-1):\n",
    "            x=self.upconvs[i](x)\n",
    "            adjusted_encoder_features = self.crop(encoder_features[i], x)\n",
    "            x = torch.cat([x, adjusted_encoder_features], dim=1)\n",
    "            x = self.dec_blocks[i](x)\n",
    "        return x\n",
    "    \n",
    "    def crop(self, adjusted_encoder_features, x):\n",
    "        _,_,H,W = x.shape\n",
    "        adjusted_encoder_features = transforms.CenterCrop([H,W])(adjusted_encoder_features)\n",
    "        return adjusted_encoder_features\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_classes is the number of channels in the output. Not really desired as we want a mask\n",
    "#change output to layer with highest value?\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, encoding_channels= (1,64,128,256,512,1024), decoding_channels = (1024, 512, 256, 128, 64), num_class = 512, retain_dim=False):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(encoding_channels)\n",
    "        self.decoder = Decoder(decoding_channels)\n",
    "        self.head = nn.Conv2d(decoding_channels[-1], num_class, 1)\n",
    "        self.retain_dim = retain_dim\n",
    "    def forward(self, x):\n",
    "        encoding_features = self.encoder(x)\n",
    "        #Note [::-1] flips the order of the encoding channels so they start with 1024\n",
    "        out = self.decoder(encoding_features[::-1][0], encoding_features[::-1][1:])\n",
    "        out = self.head(out)\n",
    "        if self.retain_dim:\n",
    "            out = F.interpolate(out, (512,512))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out how to use one layer of pretrained weights https://github.com/avijit9/forces/blob/master/model.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flatten(start_dim=1, end_dim=-1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): UNet(\n",
       "    (encoder): Encoder(\n",
       "      (enc_blocks): ModuleList(\n",
       "        (0): Block(\n",
       "          (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): Block(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): Block(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): Block(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): Block(\n",
       "          (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (upconvs): ModuleList(\n",
       "        (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (dec_blocks): ModuleList(\n",
       "        (0): Block(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): Block(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): Block(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): Block(\n",
       "          (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (head): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (1): regression_net(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "    (norm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (drop1): Dropout(p=0.25, inplace=False)\n",
       "    (linear1): Linear(in_features=512, out_features=256, bias=False)\n",
       "    (relu): ReLU()\n",
       "    (norm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (drop2): Dropout(p=0.25, inplace=False)\n",
       "    (fc): Linear(in_features=256, out_features=1, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class regression_net(nn.Module):\n",
    "    def __init__(self, y_range = (4.9, 24)):\n",
    "        super(regression_net, self).__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.norm1 = nn.BatchNorm1d(512, eps=1e-5, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.drop1 = nn.Dropout(p=0.25, inplace=False)\n",
    "        self.linear1 = nn.Linear(in_features = 512, out_features = 256, bias = False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.norm2 = nn.BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.drop2 = nn.Dropout(p=0.25, inplace=False)\n",
    "        self.fc = nn.Linear(256, 1, bias=False)\n",
    "        self.y_range = y_range\n",
    "    def forward(self, x):\n",
    "        x = self.fc(self.drop2(self.norm2(self.relu(self.linear1(self.drop1(self.norm1(self.flat(self.pool(x)))))))))\n",
    "        #print(x.shape)\n",
    "        #Final age should be between 5 and 24 hours\n",
    "   \n",
    "\n",
    "        return (torch.sigmoid(x)*(self.y_range[1]-self.y_range[0])+self.y_range[0])\n",
    "# self.pool = nn.AdaptiveAvgPool2d((32,32))\n",
    "model = UNet()\n",
    "regnet = regression_net()\n",
    "model = nn.Sequential(model, regnet)\n",
    "##########\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.to(device)\n",
    "# input = torch.from_numpy( img )[None, None, :].float()\n",
    "# input = input.to('cuda')\n",
    "# output = model(input)\n",
    "# output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "#def loss_fn (output, target): return 0.5*(output- target)**2\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2) # 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_transforms = transforms.Compose([\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Resize((512,512)),\n",
    "    transforms.Normalize(mean = 0.5, std=0.5),\n",
    "    #transforms.ColorJitter(contrast = 0.2),\n",
    "    transforms.RandomVerticalFlip(0.3),\n",
    "    transforms.RandomHorizontalFlip(0.3),\n",
    "    transforms.RandomApply([transforms.RandomRotation((90,90))], p=0.5)\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageValuePair(Dataset):\n",
    "    def __init__(self, img_paths, transforms=None):\n",
    "        self.img_paths = img_paths\n",
    "        \n",
    "        if transforms is not None:\n",
    "            self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = img_as_float(io.imread(self.img_paths[idx]))\n",
    "        age = torch.tensor(name_to_hrs(self.img_paths[idx]))\n",
    "        img = self.transforms(img)\n",
    "        return img, age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y = y.view(-1,1)\n",
    "        #print(X[200:250, 200:250])\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(pred)\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            N = len(X)\n",
    "            #print(batchLen)\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X) # N x 1 x H x W\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            #print(f\"Actual:{y:>8f} \\n Pred: {pred:>8f} \\n\")\n",
    "    test_loss /= size\n",
    "    print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train = ImageValuePair(img_train_paths,  transforms=pair_transforms)\n",
    "train_dataloader = DataLoader(image_train, batch_size=8, shuffle=True)\n",
    "image_test= ImageValuePair(img_test_paths, transforms=pair_transforms)\n",
    "test_dataloader = DataLoader(image_test, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_images = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #pick an image to view\n",
    "# n=1\n",
    "\n",
    "# train_images, train_ages= next(iter(test_dataloader))\n",
    "# agesout = model(train_images.cuda())\n",
    "# print(f\"Feature batch shape: {train_images.size()}\")\n",
    "# img = train_images[n].squeeze()\n",
    "\n",
    "# plt.imshow(img, cmap=\"gray\")\n",
    "# plt.show()\n",
    "# print(agesout[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.568094  [    0/ 1080]\n",
      "loss: 4.266264  [   80/ 1080]\n",
      "loss: 2.507753  [  160/ 1080]\n",
      "loss: 2.364590  [  240/ 1080]\n",
      "loss: 3.404545  [  320/ 1080]\n",
      "loss: 1.119358  [  400/ 1080]\n",
      "loss: 2.188883  [  480/ 1080]\n",
      "loss: 1.862412  [  560/ 1080]\n",
      "loss: 2.674530  [  640/ 1080]\n",
      "loss: 5.444207  [  720/ 1080]\n",
      "loss: 2.901593  [  800/ 1080]\n",
      "loss: 2.611867  [  880/ 1080]\n",
      "loss: 1.559303  [  960/ 1080]\n",
      "loss: 1.887712  [ 1040/ 1080]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\loss.py:96: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Avg loss: 0.891849 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.081317  [    0/ 1080]\n",
      "loss: 1.434530  [   80/ 1080]\n",
      "loss: 1.508414  [  160/ 1080]\n",
      "loss: 1.768135  [  240/ 1080]\n",
      "loss: 1.831609  [  320/ 1080]\n",
      "loss: 1.581976  [  400/ 1080]\n",
      "loss: 1.378571  [  480/ 1080]\n",
      "loss: 1.478753  [  560/ 1080]\n",
      "loss: 1.406853  [  640/ 1080]\n",
      "loss: 2.210195  [  720/ 1080]\n",
      "loss: 1.852059  [  800/ 1080]\n",
      "loss: 1.983029  [  880/ 1080]\n",
      "loss: 2.809550  [  960/ 1080]\n",
      "loss: 1.766639  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.900014 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.933715  [    0/ 1080]\n",
      "loss: 1.260950  [   80/ 1080]\n",
      "loss: 1.563570  [  160/ 1080]\n",
      "loss: 1.266353  [  240/ 1080]\n",
      "loss: 2.019856  [  320/ 1080]\n",
      "loss: 1.900375  [  400/ 1080]\n",
      "loss: 1.671173  [  480/ 1080]\n",
      "loss: 2.173006  [  560/ 1080]\n",
      "loss: 2.365309  [  640/ 1080]\n",
      "loss: 1.392095  [  720/ 1080]\n",
      "loss: 1.980165  [  800/ 1080]\n",
      "loss: 1.740018  [  880/ 1080]\n",
      "loss: 0.771976  [  960/ 1080]\n",
      "loss: 2.066819  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.908448 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.132113  [    0/ 1080]\n",
      "loss: 1.182015  [   80/ 1080]\n",
      "loss: 2.831146  [  160/ 1080]\n",
      "loss: 1.367608  [  240/ 1080]\n",
      "loss: 1.661673  [  320/ 1080]\n",
      "loss: 1.704897  [  400/ 1080]\n",
      "loss: 1.000444  [  480/ 1080]\n",
      "loss: 1.229568  [  560/ 1080]\n",
      "loss: 1.475172  [  640/ 1080]\n",
      "loss: 1.430461  [  720/ 1080]\n",
      "loss: 1.448405  [  800/ 1080]\n",
      "loss: 1.766809  [  880/ 1080]\n",
      "loss: 1.731803  [  960/ 1080]\n",
      "loss: 2.487650  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.930832 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.090244  [    0/ 1080]\n",
      "loss: 2.248429  [   80/ 1080]\n",
      "loss: 1.855400  [  160/ 1080]\n",
      "loss: 1.624814  [  240/ 1080]\n",
      "loss: 1.052978  [  320/ 1080]\n",
      "loss: 1.257590  [  400/ 1080]\n",
      "loss: 3.137074  [  480/ 1080]\n",
      "loss: 1.510506  [  560/ 1080]\n",
      "loss: 1.432364  [  640/ 1080]\n",
      "loss: 0.745451  [  720/ 1080]\n",
      "loss: 3.082219  [  800/ 1080]\n",
      "loss: 1.011224  [  880/ 1080]\n",
      "loss: 2.178009  [  960/ 1080]\n",
      "loss: 4.439567  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.645571 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.154962  [    0/ 1080]\n",
      "loss: 1.667256  [   80/ 1080]\n",
      "loss: 2.177716  [  160/ 1080]\n",
      "loss: 1.026638  [  240/ 1080]\n",
      "loss: 0.674539  [  320/ 1080]\n",
      "loss: 0.995828  [  400/ 1080]\n",
      "loss: 0.577702  [  480/ 1080]\n",
      "loss: 1.147318  [  560/ 1080]\n",
      "loss: 1.679024  [  640/ 1080]\n",
      "loss: 1.995646  [  720/ 1080]\n",
      "loss: 1.584556  [  800/ 1080]\n",
      "loss: 0.866001  [  880/ 1080]\n",
      "loss: 4.921204  [  960/ 1080]\n",
      "loss: 1.952482  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.733709 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.157624  [    0/ 1080]\n",
      "loss: 3.191104  [   80/ 1080]\n",
      "loss: 1.172499  [  160/ 1080]\n",
      "loss: 0.868766  [  240/ 1080]\n",
      "loss: 2.227413  [  320/ 1080]\n",
      "loss: 1.397848  [  400/ 1080]\n",
      "loss: 1.825325  [  480/ 1080]\n",
      "loss: 1.423522  [  560/ 1080]\n",
      "loss: 1.006305  [  640/ 1080]\n",
      "loss: 1.265902  [  720/ 1080]\n",
      "loss: 1.428347  [  800/ 1080]\n",
      "loss: 1.604680  [  880/ 1080]\n",
      "loss: 1.040472  [  960/ 1080]\n",
      "loss: 1.249139  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.933985 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.652557  [    0/ 1080]\n",
      "loss: 0.764590  [   80/ 1080]\n",
      "loss: 1.541669  [  160/ 1080]\n",
      "loss: 2.023569  [  240/ 1080]\n",
      "loss: 2.742524  [  320/ 1080]\n",
      "loss: 1.544765  [  400/ 1080]\n",
      "loss: 1.536440  [  480/ 1080]\n",
      "loss: 1.121057  [  560/ 1080]\n",
      "loss: 0.819806  [  640/ 1080]\n",
      "loss: 0.895981  [  720/ 1080]\n",
      "loss: 1.627638  [  800/ 1080]\n",
      "loss: 1.464331  [  880/ 1080]\n",
      "loss: 1.561828  [  960/ 1080]\n",
      "loss: 3.171178  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.575949 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.430319  [    0/ 1080]\n",
      "loss: 2.084562  [   80/ 1080]\n",
      "loss: 1.076201  [  160/ 1080]\n",
      "loss: 0.950680  [  240/ 1080]\n",
      "loss: 1.152433  [  320/ 1080]\n",
      "loss: 1.440718  [  400/ 1080]\n",
      "loss: 1.262044  [  480/ 1080]\n",
      "loss: 2.691684  [  560/ 1080]\n",
      "loss: 1.192408  [  640/ 1080]\n",
      "loss: 1.060176  [  720/ 1080]\n",
      "loss: 1.411805  [  800/ 1080]\n",
      "loss: 2.439987  [  880/ 1080]\n",
      "loss: 1.005671  [  960/ 1080]\n",
      "loss: 2.130131  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.918102 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.130743  [    0/ 1080]\n",
      "loss: 1.497939  [   80/ 1080]\n",
      "loss: 1.218737  [  160/ 1080]\n",
      "loss: 0.639978  [  240/ 1080]\n",
      "loss: 2.337354  [  320/ 1080]\n",
      "loss: 1.710558  [  400/ 1080]\n",
      "loss: 1.040003  [  480/ 1080]\n",
      "loss: 2.945497  [  560/ 1080]\n",
      "loss: 1.155240  [  640/ 1080]\n",
      "loss: 1.537254  [  720/ 1080]\n",
      "loss: 1.189918  [  800/ 1080]\n",
      "loss: 5.093470  [  880/ 1080]\n",
      "loss: 0.976754  [  960/ 1080]\n",
      "loss: 2.690007  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 1.431463 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.995411  [    0/ 1080]\n",
      "loss: 3.175628  [   80/ 1080]\n",
      "loss: 1.351204  [  160/ 1080]\n",
      "loss: 1.838365  [  240/ 1080]\n",
      "loss: 1.308959  [  320/ 1080]\n",
      "loss: 1.946766  [  400/ 1080]\n",
      "loss: 3.074396  [  480/ 1080]\n",
      "loss: 1.022777  [  560/ 1080]\n",
      "loss: 2.603844  [  640/ 1080]\n",
      "loss: 1.758451  [  720/ 1080]\n",
      "loss: 1.541460  [  800/ 1080]\n",
      "loss: 2.671659  [  880/ 1080]\n",
      "loss: 1.405131  [  960/ 1080]\n",
      "loss: 1.008153  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 1.369564 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.321772  [    0/ 1080]\n",
      "loss: 0.770528  [   80/ 1080]\n",
      "loss: 0.718020  [  160/ 1080]\n",
      "loss: 1.620932  [  240/ 1080]\n",
      "loss: 3.124536  [  320/ 1080]\n",
      "loss: 1.519741  [  400/ 1080]\n",
      "loss: 1.711021  [  480/ 1080]\n",
      "loss: 1.850385  [  560/ 1080]\n",
      "loss: 1.561567  [  640/ 1080]\n",
      "loss: 1.483130  [  720/ 1080]\n",
      "loss: 1.356987  [  800/ 1080]\n",
      "loss: 1.569614  [  880/ 1080]\n",
      "loss: 0.889641  [  960/ 1080]\n",
      "loss: 1.422338  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 1.194962 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.506826  [    0/ 1080]\n",
      "loss: 1.328063  [   80/ 1080]\n",
      "loss: 1.213243  [  160/ 1080]\n",
      "loss: 1.469237  [  240/ 1080]\n",
      "loss: 0.671826  [  320/ 1080]\n",
      "loss: 1.535213  [  400/ 1080]\n",
      "loss: 1.793861  [  480/ 1080]\n",
      "loss: 1.821791  [  560/ 1080]\n",
      "loss: 1.753843  [  640/ 1080]\n",
      "loss: 0.983597  [  720/ 1080]\n",
      "loss: 0.644043  [  800/ 1080]\n",
      "loss: 1.011840  [  880/ 1080]\n",
      "loss: 1.604987  [  960/ 1080]\n",
      "loss: 1.096869  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.752301 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.574912  [    0/ 1080]\n",
      "loss: 2.955471  [   80/ 1080]\n",
      "loss: 0.945066  [  160/ 1080]\n",
      "loss: 1.175827  [  240/ 1080]\n",
      "loss: 1.264015  [  320/ 1080]\n",
      "loss: 1.971038  [  400/ 1080]\n",
      "loss: 0.657862  [  480/ 1080]\n",
      "loss: 1.649127  [  560/ 1080]\n",
      "loss: 3.012808  [  640/ 1080]\n",
      "loss: 0.888778  [  720/ 1080]\n",
      "loss: 2.174934  [  800/ 1080]\n",
      "loss: 2.586978  [  880/ 1080]\n",
      "loss: 1.735335  [  960/ 1080]\n",
      "loss: 2.559537  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.760676 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.957490  [    0/ 1080]\n",
      "loss: 1.442598  [   80/ 1080]\n",
      "loss: 2.862233  [  160/ 1080]\n",
      "loss: 1.678672  [  240/ 1080]\n",
      "loss: 1.695590  [  320/ 1080]\n",
      "loss: 2.631560  [  400/ 1080]\n",
      "loss: 1.839341  [  480/ 1080]\n",
      "loss: 1.920646  [  560/ 1080]\n",
      "loss: 1.712164  [  640/ 1080]\n",
      "loss: 0.459838  [  720/ 1080]\n",
      "loss: 1.709882  [  800/ 1080]\n",
      "loss: 2.885738  [  880/ 1080]\n",
      "loss: 1.252848  [  960/ 1080]\n",
      "loss: 1.719546  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.873894 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.992927  [    0/ 1080]\n",
      "loss: 1.355188  [   80/ 1080]\n",
      "loss: 3.075979  [  160/ 1080]\n",
      "loss: 1.557389  [  240/ 1080]\n",
      "loss: 0.801977  [  320/ 1080]\n",
      "loss: 1.225307  [  400/ 1080]\n",
      "loss: 0.736898  [  480/ 1080]\n",
      "loss: 1.694413  [  560/ 1080]\n",
      "loss: 1.590689  [  640/ 1080]\n",
      "loss: 1.092578  [  720/ 1080]\n",
      "loss: 0.770125  [  800/ 1080]\n",
      "loss: 2.400507  [  880/ 1080]\n",
      "loss: 2.045351  [  960/ 1080]\n",
      "loss: 1.391461  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.665480 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.870247  [    0/ 1080]\n",
      "loss: 2.461912  [   80/ 1080]\n",
      "loss: 1.364995  [  160/ 1080]\n",
      "loss: 0.653723  [  240/ 1080]\n",
      "loss: 1.163622  [  320/ 1080]\n",
      "loss: 1.305833  [  400/ 1080]\n",
      "loss: 1.865375  [  480/ 1080]\n",
      "loss: 0.631321  [  560/ 1080]\n",
      "loss: 0.763983  [  640/ 1080]\n",
      "loss: 0.971181  [  720/ 1080]\n",
      "loss: 2.177849  [  800/ 1080]\n",
      "loss: 1.314212  [  880/ 1080]\n",
      "loss: 2.003014  [  960/ 1080]\n",
      "loss: 1.434910  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.615513 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 3.384732  [    0/ 1080]\n",
      "loss: 2.061824  [   80/ 1080]\n",
      "loss: 1.539855  [  160/ 1080]\n",
      "loss: 2.920190  [  240/ 1080]\n",
      "loss: 2.003346  [  320/ 1080]\n",
      "loss: 0.705637  [  400/ 1080]\n",
      "loss: 0.567953  [  480/ 1080]\n",
      "loss: 2.263576  [  560/ 1080]\n",
      "loss: 1.243168  [  640/ 1080]\n",
      "loss: 1.885932  [  720/ 1080]\n",
      "loss: 1.342339  [  800/ 1080]\n",
      "loss: 1.177615  [  880/ 1080]\n",
      "loss: 1.201762  [  960/ 1080]\n",
      "loss: 1.857877  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.524604 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.542170  [    0/ 1080]\n",
      "loss: 3.126280  [   80/ 1080]\n",
      "loss: 1.337476  [  160/ 1080]\n",
      "loss: 2.592289  [  240/ 1080]\n",
      "loss: 0.892031  [  320/ 1080]\n",
      "loss: 1.229739  [  400/ 1080]\n",
      "loss: 1.122024  [  480/ 1080]\n",
      "loss: 0.861493  [  560/ 1080]\n",
      "loss: 3.779834  [  640/ 1080]\n",
      "loss: 1.243512  [  720/ 1080]\n",
      "loss: 2.488492  [  800/ 1080]\n",
      "loss: 1.120926  [  880/ 1080]\n",
      "loss: 2.269161  [  960/ 1080]\n",
      "loss: 0.981536  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.544060 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.577918  [    0/ 1080]\n",
      "loss: 1.728612  [   80/ 1080]\n",
      "loss: 1.317114  [  160/ 1080]\n",
      "loss: 1.122636  [  240/ 1080]\n",
      "loss: 0.982964  [  320/ 1080]\n",
      "loss: 0.888668  [  400/ 1080]\n",
      "loss: 3.009479  [  480/ 1080]\n",
      "loss: 1.507961  [  560/ 1080]\n",
      "loss: 1.046464  [  640/ 1080]\n",
      "loss: 1.248817  [  720/ 1080]\n",
      "loss: 1.012473  [  800/ 1080]\n",
      "loss: 2.433504  [  880/ 1080]\n",
      "loss: 1.880594  [  960/ 1080]\n",
      "loss: 1.240129  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.680806 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.194348  [    0/ 1080]\n",
      "loss: 1.291686  [   80/ 1080]\n",
      "loss: 1.729840  [  160/ 1080]\n",
      "loss: 2.427441  [  240/ 1080]\n",
      "loss: 1.638189  [  320/ 1080]\n",
      "loss: 1.798622  [  400/ 1080]\n",
      "loss: 1.370964  [  480/ 1080]\n",
      "loss: 1.306987  [  560/ 1080]\n",
      "loss: 0.893267  [  640/ 1080]\n",
      "loss: 1.189831  [  720/ 1080]\n",
      "loss: 1.022095  [  800/ 1080]\n",
      "loss: 2.225572  [  880/ 1080]\n",
      "loss: 1.134902  [  960/ 1080]\n",
      "loss: 1.963649  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.540012 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1.025282  [    0/ 1080]\n",
      "loss: 1.811035  [   80/ 1080]\n",
      "loss: 0.976161  [  160/ 1080]\n",
      "loss: 2.147420  [  240/ 1080]\n",
      "loss: 1.125177  [  320/ 1080]\n",
      "loss: 1.437447  [  400/ 1080]\n",
      "loss: 2.625559  [  480/ 1080]\n",
      "loss: 0.990685  [  560/ 1080]\n",
      "loss: 1.353706  [  640/ 1080]\n",
      "loss: 1.473195  [  720/ 1080]\n",
      "loss: 1.354030  [  800/ 1080]\n",
      "loss: 2.876294  [  880/ 1080]\n",
      "loss: 1.289741  [  960/ 1080]\n",
      "loss: 3.157840  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.834982 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.150543  [    0/ 1080]\n",
      "loss: 1.503693  [   80/ 1080]\n",
      "loss: 1.071642  [  160/ 1080]\n",
      "loss: 1.621089  [  240/ 1080]\n",
      "loss: 2.813479  [  320/ 1080]\n",
      "loss: 3.007768  [  400/ 1080]\n",
      "loss: 1.797915  [  480/ 1080]\n",
      "loss: 1.659951  [  560/ 1080]\n",
      "loss: 2.061227  [  640/ 1080]\n",
      "loss: 1.050478  [  720/ 1080]\n",
      "loss: 1.427735  [  800/ 1080]\n",
      "loss: 0.737374  [  880/ 1080]\n",
      "loss: 0.798615  [  960/ 1080]\n",
      "loss: 2.674812  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.902319 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.862465  [    0/ 1080]\n",
      "loss: 1.579508  [   80/ 1080]\n",
      "loss: 2.569782  [  160/ 1080]\n",
      "loss: 2.692198  [  240/ 1080]\n",
      "loss: 2.514234  [  320/ 1080]\n",
      "loss: 2.031651  [  400/ 1080]\n",
      "loss: 1.693701  [  480/ 1080]\n",
      "loss: 2.172801  [  560/ 1080]\n",
      "loss: 3.198576  [  640/ 1080]\n",
      "loss: 1.398034  [  720/ 1080]\n",
      "loss: 1.537318  [  800/ 1080]\n",
      "loss: 2.539761  [  880/ 1080]\n",
      "loss: 1.338866  [  960/ 1080]\n",
      "loss: 2.207009  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 1.407137 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1.081170  [    0/ 1080]\n",
      "loss: 2.278598  [   80/ 1080]\n",
      "loss: 1.033620  [  160/ 1080]\n",
      "loss: 1.785367  [  240/ 1080]\n",
      "loss: 3.389910  [  320/ 1080]\n",
      "loss: 2.997117  [  400/ 1080]\n",
      "loss: 3.133453  [  480/ 1080]\n",
      "loss: 0.992491  [  560/ 1080]\n",
      "loss: 1.104269  [  640/ 1080]\n",
      "loss: 1.394381  [  720/ 1080]\n",
      "loss: 2.452485  [  800/ 1080]\n",
      "loss: 2.621163  [  880/ 1080]\n",
      "loss: 1.983081  [  960/ 1080]\n",
      "loss: 1.548247  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.758512 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 1.225553  [    0/ 1080]\n",
      "loss: 1.526840  [   80/ 1080]\n",
      "loss: 2.210299  [  160/ 1080]\n",
      "loss: 1.280514  [  240/ 1080]\n",
      "loss: 0.818645  [  320/ 1080]\n",
      "loss: 1.270840  [  400/ 1080]\n",
      "loss: 1.115475  [  480/ 1080]\n",
      "loss: 2.678398  [  560/ 1080]\n",
      "loss: 0.737080  [  640/ 1080]\n",
      "loss: 0.964570  [  720/ 1080]\n",
      "loss: 1.254927  [  800/ 1080]\n",
      "loss: 2.053913  [  880/ 1080]\n",
      "loss: 1.425819  [  960/ 1080]\n",
      "loss: 3.036915  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.932223 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1.398196  [    0/ 1080]\n",
      "loss: 3.214095  [   80/ 1080]\n",
      "loss: 1.731221  [  160/ 1080]\n",
      "loss: 1.649655  [  240/ 1080]\n",
      "loss: 1.745508  [  320/ 1080]\n",
      "loss: 0.932972  [  400/ 1080]\n",
      "loss: 1.590379  [  480/ 1080]\n",
      "loss: 1.154366  [  560/ 1080]\n",
      "loss: 1.636627  [  640/ 1080]\n",
      "loss: 1.824012  [  720/ 1080]\n",
      "loss: 1.229006  [  800/ 1080]\n",
      "loss: 1.390379  [  880/ 1080]\n",
      "loss: 2.096858  [  960/ 1080]\n",
      "loss: 1.754330  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.830670 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 1.620278  [    0/ 1080]\n",
      "loss: 0.934856  [   80/ 1080]\n",
      "loss: 0.963818  [  160/ 1080]\n",
      "loss: 3.546523  [  240/ 1080]\n",
      "loss: 1.377870  [  320/ 1080]\n",
      "loss: 1.918271  [  400/ 1080]\n",
      "loss: 1.223288  [  480/ 1080]\n",
      "loss: 0.774069  [  560/ 1080]\n",
      "loss: 1.256010  [  640/ 1080]\n",
      "loss: 1.322258  [  720/ 1080]\n",
      "loss: 1.368204  [  800/ 1080]\n",
      "loss: 2.688609  [  880/ 1080]\n",
      "loss: 1.212589  [  960/ 1080]\n",
      "loss: 1.345438  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.555318 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 2.206783  [    0/ 1080]\n",
      "loss: 0.859968  [   80/ 1080]\n",
      "loss: 1.924190  [  160/ 1080]\n",
      "loss: 2.446349  [  240/ 1080]\n",
      "loss: 1.112213  [  320/ 1080]\n",
      "loss: 1.144450  [  400/ 1080]\n",
      "loss: 3.277428  [  480/ 1080]\n",
      "loss: 1.613610  [  560/ 1080]\n",
      "loss: 1.480341  [  640/ 1080]\n",
      "loss: 0.870454  [  720/ 1080]\n",
      "loss: 1.086751  [  800/ 1080]\n",
      "loss: 0.825108  [  880/ 1080]\n",
      "loss: 1.273241  [  960/ 1080]\n",
      "loss: 0.784504  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934375 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 3.021789  [    0/ 1080]\n",
      "loss: 3.059032  [   80/ 1080]\n",
      "loss: 2.019690  [  160/ 1080]\n",
      "loss: 3.290361  [  240/ 1080]\n",
      "loss: 2.951762  [  320/ 1080]\n",
      "loss: 0.935853  [  400/ 1080]\n",
      "loss: 2.785115  [  480/ 1080]\n",
      "loss: 0.963600  [  560/ 1080]\n",
      "loss: 1.054012  [  640/ 1080]\n",
      "loss: 0.557640  [  720/ 1080]\n",
      "loss: 2.238361  [  800/ 1080]\n",
      "loss: 2.445770  [  880/ 1080]\n",
      "loss: 3.061533  [  960/ 1080]\n",
      "loss: 0.665542  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.689388 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 1.287329  [    0/ 1080]\n",
      "loss: 0.980569  [   80/ 1080]\n",
      "loss: 3.161858  [  160/ 1080]\n",
      "loss: 3.043059  [  240/ 1080]\n",
      "loss: 2.479679  [  320/ 1080]\n",
      "loss: 0.779989  [  400/ 1080]\n",
      "loss: 0.811744  [  480/ 1080]\n",
      "loss: 3.334279  [  560/ 1080]\n",
      "loss: 1.062715  [  640/ 1080]\n",
      "loss: 1.021376  [  720/ 1080]\n",
      "loss: 1.529857  [  800/ 1080]\n",
      "loss: 1.115413  [  880/ 1080]\n",
      "loss: 1.207734  [  960/ 1080]\n",
      "loss: 1.065110  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 1.315532 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 1.030264  [    0/ 1080]\n",
      "loss: 1.513735  [   80/ 1080]\n",
      "loss: 0.729666  [  160/ 1080]\n",
      "loss: 1.091541  [  240/ 1080]\n",
      "loss: 1.634003  [  320/ 1080]\n",
      "loss: 0.680846  [  400/ 1080]\n",
      "loss: 0.491625  [  480/ 1080]\n",
      "loss: 0.804543  [  560/ 1080]\n",
      "loss: 0.763696  [  640/ 1080]\n",
      "loss: 1.547689  [  720/ 1080]\n",
      "loss: 0.913438  [  800/ 1080]\n",
      "loss: 1.394902  [  880/ 1080]\n",
      "loss: 1.856419  [  960/ 1080]\n",
      "loss: 0.657962  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934375 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 1.646169  [    0/ 1080]\n",
      "loss: 0.892549  [   80/ 1080]\n",
      "loss: 3.055705  [  160/ 1080]\n",
      "loss: 1.052636  [  240/ 1080]\n",
      "loss: 0.746665  [  320/ 1080]\n",
      "loss: 2.036178  [  400/ 1080]\n",
      "loss: 0.889538  [  480/ 1080]\n",
      "loss: 1.495643  [  560/ 1080]\n",
      "loss: 1.265415  [  640/ 1080]\n",
      "loss: 2.221465  [  720/ 1080]\n",
      "loss: 0.837776  [  800/ 1080]\n",
      "loss: 1.377754  [  880/ 1080]\n",
      "loss: 1.039639  [  960/ 1080]\n",
      "loss: 0.661660  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.924586 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 2.222631  [    0/ 1080]\n",
      "loss: 1.191527  [   80/ 1080]\n",
      "loss: 1.311703  [  160/ 1080]\n",
      "loss: 2.127119  [  240/ 1080]\n",
      "loss: 1.601336  [  320/ 1080]\n",
      "loss: 3.066763  [  400/ 1080]\n",
      "loss: 1.503807  [  480/ 1080]\n",
      "loss: 1.698122  [  560/ 1080]\n",
      "loss: 1.666196  [  640/ 1080]\n",
      "loss: 1.627741  [  720/ 1080]\n",
      "loss: 1.055864  [  800/ 1080]\n",
      "loss: 2.100452  [  880/ 1080]\n",
      "loss: 1.688407  [  960/ 1080]\n",
      "loss: 1.487509  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934375 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 1.092137  [    0/ 1080]\n",
      "loss: 1.734165  [   80/ 1080]\n",
      "loss: 0.690772  [  160/ 1080]\n",
      "loss: 1.179788  [  240/ 1080]\n",
      "loss: 0.891425  [  320/ 1080]\n",
      "loss: 2.424606  [  400/ 1080]\n",
      "loss: 1.752126  [  480/ 1080]\n",
      "loss: 1.551671  [  560/ 1080]\n",
      "loss: 1.383711  [  640/ 1080]\n",
      "loss: 1.514561  [  720/ 1080]\n",
      "loss: 1.467565  [  800/ 1080]\n",
      "loss: 3.039530  [  880/ 1080]\n",
      "loss: 0.794996  [  960/ 1080]\n",
      "loss: 1.501066  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.669562 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 3.185887  [    0/ 1080]\n",
      "loss: 1.257451  [   80/ 1080]\n",
      "loss: 1.147096  [  160/ 1080]\n",
      "loss: 1.495704  [  240/ 1080]\n",
      "loss: 1.400843  [  320/ 1080]\n",
      "loss: 2.297253  [  400/ 1080]\n",
      "loss: 1.209751  [  480/ 1080]\n",
      "loss: 0.752867  [  560/ 1080]\n",
      "loss: 2.133471  [  640/ 1080]\n",
      "loss: 1.475937  [  720/ 1080]\n",
      "loss: 0.684110  [  800/ 1080]\n",
      "loss: 0.947986  [  880/ 1080]\n",
      "loss: 0.563543  [  960/ 1080]\n",
      "loss: 2.591352  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934375 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 1.186401  [    0/ 1080]\n",
      "loss: 0.981080  [   80/ 1080]\n",
      "loss: 0.811333  [  160/ 1080]\n",
      "loss: 2.275616  [  240/ 1080]\n",
      "loss: 0.978555  [  320/ 1080]\n",
      "loss: 0.960929  [  400/ 1080]\n",
      "loss: 2.237577  [  480/ 1080]\n",
      "loss: 0.762948  [  560/ 1080]\n",
      "loss: 2.051150  [  640/ 1080]\n",
      "loss: 1.771415  [  720/ 1080]\n",
      "loss: 1.302547  [  800/ 1080]\n",
      "loss: 0.888604  [  880/ 1080]\n",
      "loss: 2.036381  [  960/ 1080]\n",
      "loss: 0.713502  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.904570 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 1.767988  [    0/ 1080]\n",
      "loss: 0.678949  [   80/ 1080]\n",
      "loss: 1.102439  [  160/ 1080]\n",
      "loss: 1.048049  [  240/ 1080]\n",
      "loss: 1.550836  [  320/ 1080]\n",
      "loss: 0.488352  [  400/ 1080]\n",
      "loss: 2.088331  [  480/ 1080]\n",
      "loss: 2.810347  [  560/ 1080]\n",
      "loss: 2.738522  [  640/ 1080]\n",
      "loss: 1.849212  [  720/ 1080]\n",
      "loss: 1.739748  [  800/ 1080]\n",
      "loss: 1.550892  [  880/ 1080]\n",
      "loss: 1.026566  [  960/ 1080]\n",
      "loss: 1.236585  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.533474 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.565831  [    0/ 1080]\n",
      "loss: 1.506483  [   80/ 1080]\n",
      "loss: 0.993259  [  160/ 1080]\n",
      "loss: 0.851328  [  240/ 1080]\n",
      "loss: 1.281504  [  320/ 1080]\n",
      "loss: 1.822122  [  400/ 1080]\n",
      "loss: 0.863615  [  480/ 1080]\n",
      "loss: 1.100560  [  560/ 1080]\n",
      "loss: 1.829673  [  640/ 1080]\n",
      "loss: 1.549786  [  720/ 1080]\n",
      "loss: 2.914729  [  800/ 1080]\n",
      "loss: 1.437046  [  880/ 1080]\n",
      "loss: 1.202141  [  960/ 1080]\n",
      "loss: 3.386727  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.669208 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 1.440176  [    0/ 1080]\n",
      "loss: 1.679435  [   80/ 1080]\n",
      "loss: 1.333106  [  160/ 1080]\n",
      "loss: 1.684622  [  240/ 1080]\n",
      "loss: 2.444156  [  320/ 1080]\n",
      "loss: 1.588312  [  400/ 1080]\n",
      "loss: 1.225408  [  480/ 1080]\n",
      "loss: 1.575747  [  560/ 1080]\n",
      "loss: 2.766659  [  640/ 1080]\n",
      "loss: 0.900844  [  720/ 1080]\n",
      "loss: 1.632167  [  800/ 1080]\n",
      "loss: 1.774992  [  880/ 1080]\n",
      "loss: 1.810562  [  960/ 1080]\n",
      "loss: 1.379867  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.885892 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 1.332022  [    0/ 1080]\n",
      "loss: 0.920774  [   80/ 1080]\n",
      "loss: 1.489969  [  160/ 1080]\n",
      "loss: 2.282419  [  240/ 1080]\n",
      "loss: 1.919681  [  320/ 1080]\n",
      "loss: 1.500656  [  400/ 1080]\n",
      "loss: 1.163905  [  480/ 1080]\n",
      "loss: 1.215750  [  560/ 1080]\n",
      "loss: 1.276295  [  640/ 1080]\n",
      "loss: 1.266977  [  720/ 1080]\n",
      "loss: 2.461998  [  800/ 1080]\n",
      "loss: 2.615999  [  880/ 1080]\n",
      "loss: 0.931539  [  960/ 1080]\n",
      "loss: 3.541713  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.663071 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 1.195306  [    0/ 1080]\n",
      "loss: 2.069434  [   80/ 1080]\n",
      "loss: 1.593994  [  160/ 1080]\n",
      "loss: 1.678342  [  240/ 1080]\n",
      "loss: 2.352524  [  320/ 1080]\n",
      "loss: 0.858142  [  400/ 1080]\n",
      "loss: 1.263729  [  480/ 1080]\n",
      "loss: 0.912297  [  560/ 1080]\n",
      "loss: 1.545920  [  640/ 1080]\n",
      "loss: 4.032485  [  720/ 1080]\n",
      "loss: 0.994286  [  800/ 1080]\n",
      "loss: 0.869107  [  880/ 1080]\n",
      "loss: 2.077008  [  960/ 1080]\n",
      "loss: 2.077766  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.796416 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 1.499688  [    0/ 1080]\n",
      "loss: 1.766014  [   80/ 1080]\n",
      "loss: 1.746142  [  160/ 1080]\n",
      "loss: 1.606184  [  240/ 1080]\n",
      "loss: 2.053498  [  320/ 1080]\n",
      "loss: 1.885201  [  400/ 1080]\n",
      "loss: 2.205850  [  480/ 1080]\n",
      "loss: 2.363197  [  560/ 1080]\n",
      "loss: 1.213521  [  640/ 1080]\n",
      "loss: 1.556805  [  720/ 1080]\n",
      "loss: 0.866385  [  800/ 1080]\n",
      "loss: 1.846525  [  880/ 1080]\n",
      "loss: 3.143056  [  960/ 1080]\n",
      "loss: 1.272476  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 1.278606 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 1.171005  [    0/ 1080]\n",
      "loss: 1.773116  [   80/ 1080]\n",
      "loss: 2.405188  [  160/ 1080]\n",
      "loss: 1.800253  [  240/ 1080]\n",
      "loss: 1.178412  [  320/ 1080]\n",
      "loss: 0.691434  [  400/ 1080]\n",
      "loss: 1.593184  [  480/ 1080]\n",
      "loss: 0.849844  [  560/ 1080]\n",
      "loss: 0.996330  [  640/ 1080]\n",
      "loss: 1.679794  [  720/ 1080]\n",
      "loss: 1.410803  [  800/ 1080]\n",
      "loss: 1.629975  [  880/ 1080]\n",
      "loss: 2.599885  [  960/ 1080]\n",
      "loss: 0.969327  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.534872 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 2.291865  [    0/ 1080]\n",
      "loss: 2.310031  [   80/ 1080]\n",
      "loss: 0.896973  [  160/ 1080]\n",
      "loss: 1.478302  [  240/ 1080]\n",
      "loss: 1.500602  [  320/ 1080]\n",
      "loss: 1.286644  [  400/ 1080]\n",
      "loss: 1.571598  [  480/ 1080]\n",
      "loss: 1.257519  [  560/ 1080]\n",
      "loss: 1.482008  [  640/ 1080]\n",
      "loss: 1.265482  [  720/ 1080]\n",
      "loss: 2.076384  [  800/ 1080]\n",
      "loss: 1.103933  [  880/ 1080]\n",
      "loss: 0.828945  [  960/ 1080]\n",
      "loss: 1.318470  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934371 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 1.929917  [    0/ 1080]\n",
      "loss: 2.150930  [   80/ 1080]\n",
      "loss: 1.128058  [  160/ 1080]\n",
      "loss: 0.897778  [  240/ 1080]\n",
      "loss: 1.218591  [  320/ 1080]\n",
      "loss: 2.071950  [  400/ 1080]\n",
      "loss: 1.339122  [  480/ 1080]\n",
      "loss: 1.231105  [  560/ 1080]\n",
      "loss: 0.613743  [  640/ 1080]\n",
      "loss: 1.328334  [  720/ 1080]\n",
      "loss: 1.021083  [  800/ 1080]\n",
      "loss: 1.126217  [  880/ 1080]\n",
      "loss: 2.285137  [  960/ 1080]\n",
      "loss: 1.404358  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934375 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 1.337634  [    0/ 1080]\n",
      "loss: 1.054072  [   80/ 1080]\n",
      "loss: 1.856651  [  160/ 1080]\n",
      "loss: 1.080108  [  240/ 1080]\n",
      "loss: 2.277860  [  320/ 1080]\n",
      "loss: 0.738118  [  400/ 1080]\n",
      "loss: 0.697565  [  480/ 1080]\n",
      "loss: 2.442875  [  560/ 1080]\n",
      "loss: 1.025110  [  640/ 1080]\n",
      "loss: 1.849333  [  720/ 1080]\n",
      "loss: 1.631012  [  800/ 1080]\n",
      "loss: 0.569891  [  880/ 1080]\n",
      "loss: 0.920590  [  960/ 1080]\n",
      "loss: 2.130079  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 1.383045 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 1.818197  [    0/ 1080]\n",
      "loss: 1.656209  [   80/ 1080]\n",
      "loss: 0.746842  [  160/ 1080]\n",
      "loss: 0.884786  [  240/ 1080]\n",
      "loss: 1.149003  [  320/ 1080]\n",
      "loss: 1.302561  [  400/ 1080]\n",
      "loss: 1.706303  [  480/ 1080]\n",
      "loss: 1.040087  [  560/ 1080]\n",
      "loss: 1.076380  [  640/ 1080]\n",
      "loss: 1.180472  [  720/ 1080]\n",
      "loss: 4.072258  [  800/ 1080]\n",
      "loss: 1.228639  [  880/ 1080]\n",
      "loss: 0.993395  [  960/ 1080]\n",
      "loss: 1.227235  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 1.450525 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 1.400948  [    0/ 1080]\n",
      "loss: 1.657143  [   80/ 1080]\n",
      "loss: 0.918988  [  160/ 1080]\n",
      "loss: 4.074039  [  240/ 1080]\n",
      "loss: 0.910337  [  320/ 1080]\n",
      "loss: 1.071579  [  400/ 1080]\n",
      "loss: 1.200089  [  480/ 1080]\n",
      "loss: 2.737186  [  560/ 1080]\n",
      "loss: 1.381941  [  640/ 1080]\n",
      "loss: 0.494154  [  720/ 1080]\n",
      "loss: 1.645238  [  800/ 1080]\n",
      "loss: 1.538134  [  880/ 1080]\n",
      "loss: 1.664686  [  960/ 1080]\n",
      "loss: 2.467847  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934375 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 1.034071  [    0/ 1080]\n",
      "loss: 0.967235  [   80/ 1080]\n",
      "loss: 1.384950  [  160/ 1080]\n",
      "loss: 1.363446  [  240/ 1080]\n",
      "loss: 2.210637  [  320/ 1080]\n",
      "loss: 0.843961  [  400/ 1080]\n",
      "loss: 1.809026  [  480/ 1080]\n",
      "loss: 2.915356  [  560/ 1080]\n",
      "loss: 0.865682  [  640/ 1080]\n",
      "loss: 1.999575  [  720/ 1080]\n",
      "loss: 1.123054  [  800/ 1080]\n",
      "loss: 0.913883  [  880/ 1080]\n",
      "loss: 1.673525  [  960/ 1080]\n",
      "loss: 0.967313  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.874358 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 1.794315  [    0/ 1080]\n",
      "loss: 1.052990  [   80/ 1080]\n",
      "loss: 1.363813  [  160/ 1080]\n",
      "loss: 0.526435  [  240/ 1080]\n",
      "loss: 2.441951  [  320/ 1080]\n",
      "loss: 1.496415  [  400/ 1080]\n",
      "loss: 1.714254  [  480/ 1080]\n",
      "loss: 1.041216  [  560/ 1080]\n",
      "loss: 1.557863  [  640/ 1080]\n",
      "loss: 0.949407  [  720/ 1080]\n",
      "loss: 1.336055  [  800/ 1080]\n",
      "loss: 2.007999  [  880/ 1080]\n",
      "loss: 1.057702  [  960/ 1080]\n",
      "loss: 0.875194  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.919744 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 1.434016  [    0/ 1080]\n",
      "loss: 2.433249  [   80/ 1080]\n",
      "loss: 1.422962  [  160/ 1080]\n",
      "loss: 3.200710  [  240/ 1080]\n",
      "loss: 1.591170  [  320/ 1080]\n",
      "loss: 1.585566  [  400/ 1080]\n",
      "loss: 1.735605  [  480/ 1080]\n",
      "loss: 2.999680  [  560/ 1080]\n",
      "loss: 1.986010  [  640/ 1080]\n",
      "loss: 1.426416  [  720/ 1080]\n",
      "loss: 1.584136  [  800/ 1080]\n",
      "loss: 1.036736  [  880/ 1080]\n",
      "loss: 2.142745  [  960/ 1080]\n",
      "loss: 1.652001  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.874413 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.883396  [    0/ 1080]\n",
      "loss: 1.141239  [   80/ 1080]\n",
      "loss: 1.051727  [  160/ 1080]\n",
      "loss: 1.629284  [  240/ 1080]\n",
      "loss: 1.317950  [  320/ 1080]\n",
      "loss: 1.135211  [  400/ 1080]\n",
      "loss: 1.421362  [  480/ 1080]\n",
      "loss: 2.587563  [  560/ 1080]\n",
      "loss: 1.269892  [  640/ 1080]\n",
      "loss: 0.970721  [  720/ 1080]\n",
      "loss: 1.056002  [  800/ 1080]\n",
      "loss: 1.027033  [  880/ 1080]\n",
      "loss: 1.022918  [  960/ 1080]\n",
      "loss: 1.221349  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934373 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 1.670300  [    0/ 1080]\n",
      "loss: 1.989315  [   80/ 1080]\n",
      "loss: 0.810596  [  160/ 1080]\n",
      "loss: 0.928599  [  240/ 1080]\n",
      "loss: 1.668893  [  320/ 1080]\n",
      "loss: 1.081948  [  400/ 1080]\n",
      "loss: 1.235927  [  480/ 1080]\n",
      "loss: 0.988826  [  560/ 1080]\n",
      "loss: 0.908016  [  640/ 1080]\n",
      "loss: 1.274707  [  720/ 1080]\n",
      "loss: 1.519392  [  800/ 1080]\n",
      "loss: 0.751328  [  880/ 1080]\n",
      "loss: 1.000549  [  960/ 1080]\n",
      "loss: 1.256138  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.758447 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 1.607560  [    0/ 1080]\n",
      "loss: 1.309451  [   80/ 1080]\n",
      "loss: 1.909464  [  160/ 1080]\n",
      "loss: 1.546827  [  240/ 1080]\n",
      "loss: 0.924854  [  320/ 1080]\n",
      "loss: 2.538137  [  400/ 1080]\n",
      "loss: 1.601804  [  480/ 1080]\n",
      "loss: 1.160279  [  560/ 1080]\n",
      "loss: 1.422461  [  640/ 1080]\n",
      "loss: 1.391893  [  720/ 1080]\n",
      "loss: 1.390999  [  800/ 1080]\n",
      "loss: 1.171114  [  880/ 1080]\n",
      "loss: 2.969551  [  960/ 1080]\n",
      "loss: 1.231225  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.929687 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 2.656604  [    0/ 1080]\n",
      "loss: 2.631270  [   80/ 1080]\n",
      "loss: 0.722262  [  160/ 1080]\n",
      "loss: 1.410930  [  240/ 1080]\n",
      "loss: 1.443085  [  320/ 1080]\n",
      "loss: 1.780929  [  400/ 1080]\n",
      "loss: 1.196197  [  480/ 1080]\n",
      "loss: 1.065354  [  560/ 1080]\n",
      "loss: 0.972210  [  640/ 1080]\n",
      "loss: 1.046067  [  720/ 1080]\n",
      "loss: 2.337752  [  800/ 1080]\n",
      "loss: 0.896620  [  880/ 1080]\n",
      "loss: 0.864533  [  960/ 1080]\n",
      "loss: 1.403566  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.920465 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 1.185538  [    0/ 1080]\n",
      "loss: 1.012872  [   80/ 1080]\n",
      "loss: 1.745528  [  160/ 1080]\n",
      "loss: 1.430716  [  240/ 1080]\n",
      "loss: 2.341937  [  320/ 1080]\n",
      "loss: 2.004875  [  400/ 1080]\n",
      "loss: 2.799123  [  480/ 1080]\n",
      "loss: 1.169135  [  560/ 1080]\n",
      "loss: 0.792363  [  640/ 1080]\n",
      "loss: 1.071608  [  720/ 1080]\n",
      "loss: 1.263978  [  800/ 1080]\n",
      "loss: 0.688359  [  880/ 1080]\n",
      "loss: 0.900567  [  960/ 1080]\n",
      "loss: 1.558336  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.923843 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 1.655206  [    0/ 1080]\n",
      "loss: 1.963888  [   80/ 1080]\n",
      "loss: 2.673372  [  160/ 1080]\n",
      "loss: 1.126650  [  240/ 1080]\n",
      "loss: 1.890770  [  320/ 1080]\n",
      "loss: 0.682526  [  400/ 1080]\n",
      "loss: 1.687966  [  480/ 1080]\n",
      "loss: 1.839511  [  560/ 1080]\n",
      "loss: 0.882061  [  640/ 1080]\n",
      "loss: 1.236353  [  720/ 1080]\n",
      "loss: 1.914174  [  800/ 1080]\n",
      "loss: 1.126028  [  880/ 1080]\n",
      "loss: 1.588638  [  960/ 1080]\n",
      "loss: 0.673455  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.908790 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.833726  [    0/ 1080]\n",
      "loss: 0.531542  [   80/ 1080]\n",
      "loss: 1.068243  [  160/ 1080]\n",
      "loss: 2.673932  [  240/ 1080]\n",
      "loss: 1.542636  [  320/ 1080]\n",
      "loss: 0.836487  [  400/ 1080]\n",
      "loss: 2.497014  [  480/ 1080]\n",
      "loss: 1.790958  [  560/ 1080]\n",
      "loss: 1.739938  [  640/ 1080]\n",
      "loss: 0.827992  [  720/ 1080]\n",
      "loss: 2.824046  [  800/ 1080]\n",
      "loss: 2.027699  [  880/ 1080]\n",
      "loss: 1.638684  [  960/ 1080]\n",
      "loss: 0.750483  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.510643 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 1.123905  [    0/ 1080]\n",
      "loss: 1.528897  [   80/ 1080]\n",
      "loss: 1.634851  [  160/ 1080]\n",
      "loss: 1.674016  [  240/ 1080]\n",
      "loss: 0.888796  [  320/ 1080]\n",
      "loss: 0.807030  [  400/ 1080]\n",
      "loss: 0.944497  [  480/ 1080]\n",
      "loss: 1.140451  [  560/ 1080]\n",
      "loss: 0.979833  [  640/ 1080]\n",
      "loss: 1.439248  [  720/ 1080]\n",
      "loss: 1.804080  [  800/ 1080]\n",
      "loss: 3.285116  [  880/ 1080]\n",
      "loss: 1.124296  [  960/ 1080]\n",
      "loss: 1.992527  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934375 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 1.823462  [    0/ 1080]\n",
      "loss: 1.764841  [   80/ 1080]\n",
      "loss: 0.526913  [  160/ 1080]\n",
      "loss: 1.039601  [  240/ 1080]\n",
      "loss: 0.651424  [  320/ 1080]\n",
      "loss: 1.129424  [  400/ 1080]\n",
      "loss: 1.269738  [  480/ 1080]\n",
      "loss: 1.140624  [  560/ 1080]\n",
      "loss: 1.602041  [  640/ 1080]\n",
      "loss: 1.031008  [  720/ 1080]\n",
      "loss: 1.493849  [  800/ 1080]\n",
      "loss: 2.166249  [  880/ 1080]\n",
      "loss: 3.049446  [  960/ 1080]\n",
      "loss: 1.948797  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.631407 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 2.134782  [    0/ 1080]\n",
      "loss: 1.316475  [   80/ 1080]\n",
      "loss: 2.264604  [  160/ 1080]\n",
      "loss: 1.500584  [  240/ 1080]\n",
      "loss: 1.288074  [  320/ 1080]\n",
      "loss: 0.942654  [  400/ 1080]\n",
      "loss: 3.009964  [  480/ 1080]\n",
      "loss: 2.364802  [  560/ 1080]\n",
      "loss: 1.559675  [  640/ 1080]\n",
      "loss: 0.669917  [  720/ 1080]\n",
      "loss: 1.312683  [  800/ 1080]\n",
      "loss: 1.305729  [  880/ 1080]\n",
      "loss: 0.680150  [  960/ 1080]\n",
      "loss: 1.720510  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.813609 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 1.382012  [    0/ 1080]\n",
      "loss: 0.894248  [   80/ 1080]\n",
      "loss: 1.552341  [  160/ 1080]\n",
      "loss: 1.382387  [  240/ 1080]\n",
      "loss: 1.084831  [  320/ 1080]\n",
      "loss: 1.311931  [  400/ 1080]\n",
      "loss: 1.150270  [  480/ 1080]\n",
      "loss: 1.242572  [  560/ 1080]\n",
      "loss: 0.947467  [  640/ 1080]\n",
      "loss: 1.262232  [  720/ 1080]\n",
      "loss: 2.039627  [  800/ 1080]\n",
      "loss: 0.963054  [  880/ 1080]\n",
      "loss: 3.576527  [  960/ 1080]\n",
      "loss: 0.928976  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.565798 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 2.360901  [    0/ 1080]\n",
      "loss: 1.212614  [   80/ 1080]\n",
      "loss: 4.443406  [  160/ 1080]\n",
      "loss: 0.685227  [  240/ 1080]\n",
      "loss: 2.240459  [  320/ 1080]\n",
      "loss: 1.614344  [  400/ 1080]\n",
      "loss: 1.428978  [  480/ 1080]\n",
      "loss: 1.841334  [  560/ 1080]\n",
      "loss: 0.573994  [  640/ 1080]\n",
      "loss: 1.912498  [  720/ 1080]\n",
      "loss: 1.058396  [  800/ 1080]\n",
      "loss: 0.480487  [  880/ 1080]\n",
      "loss: 2.280263  [  960/ 1080]\n",
      "loss: 2.064613  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934375 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.451481  [    0/ 1080]\n",
      "loss: 0.860787  [   80/ 1080]\n",
      "loss: 1.353547  [  160/ 1080]\n",
      "loss: 0.970703  [  240/ 1080]\n",
      "loss: 1.745884  [  320/ 1080]\n",
      "loss: 0.884535  [  400/ 1080]\n",
      "loss: 1.550859  [  480/ 1080]\n",
      "loss: 1.936791  [  560/ 1080]\n",
      "loss: 1.740757  [  640/ 1080]\n",
      "loss: 1.234495  [  720/ 1080]\n",
      "loss: 0.982018  [  800/ 1080]\n",
      "loss: 1.226240  [  880/ 1080]\n",
      "loss: 2.405120  [  960/ 1080]\n",
      "loss: 2.236315  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.770817 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.823612  [    0/ 1080]\n",
      "loss: 1.078056  [   80/ 1080]\n",
      "loss: 1.397162  [  160/ 1080]\n",
      "loss: 2.385848  [  240/ 1080]\n",
      "loss: 1.799824  [  320/ 1080]\n",
      "loss: 2.284420  [  400/ 1080]\n",
      "loss: 0.872749  [  480/ 1080]\n",
      "loss: 0.999592  [  560/ 1080]\n",
      "loss: 1.092361  [  640/ 1080]\n",
      "loss: 1.119522  [  720/ 1080]\n",
      "loss: 1.322295  [  800/ 1080]\n",
      "loss: 1.296762  [  880/ 1080]\n",
      "loss: 1.501031  [  960/ 1080]\n",
      "loss: 1.908735  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.800922 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.636204  [    0/ 1080]\n",
      "loss: 1.591998  [   80/ 1080]\n",
      "loss: 2.461658  [  160/ 1080]\n",
      "loss: 0.794689  [  240/ 1080]\n",
      "loss: 0.651404  [  320/ 1080]\n",
      "loss: 1.163876  [  400/ 1080]\n",
      "loss: 1.500203  [  480/ 1080]\n",
      "loss: 0.900218  [  560/ 1080]\n",
      "loss: 0.811828  [  640/ 1080]\n",
      "loss: 1.058565  [  720/ 1080]\n",
      "loss: 1.272626  [  800/ 1080]\n",
      "loss: 2.796348  [  880/ 1080]\n",
      "loss: 1.638656  [  960/ 1080]\n",
      "loss: 1.744675  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.861613 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 1.915567  [    0/ 1080]\n",
      "loss: 0.935400  [   80/ 1080]\n",
      "loss: 1.631580  [  160/ 1080]\n",
      "loss: 0.880534  [  240/ 1080]\n",
      "loss: 1.689495  [  320/ 1080]\n",
      "loss: 2.831547  [  400/ 1080]\n",
      "loss: 0.948169  [  480/ 1080]\n",
      "loss: 1.300154  [  560/ 1080]\n",
      "loss: 1.095161  [  640/ 1080]\n",
      "loss: 0.804648  [  720/ 1080]\n",
      "loss: 1.416722  [  800/ 1080]\n",
      "loss: 3.273152  [  880/ 1080]\n",
      "loss: 1.584964  [  960/ 1080]\n",
      "loss: 1.001445  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 1.001071 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 2.002802  [    0/ 1080]\n",
      "loss: 0.924589  [   80/ 1080]\n",
      "loss: 1.863854  [  160/ 1080]\n",
      "loss: 0.880230  [  240/ 1080]\n",
      "loss: 0.408073  [  320/ 1080]\n",
      "loss: 1.935416  [  400/ 1080]\n",
      "loss: 2.687105  [  480/ 1080]\n",
      "loss: 1.181466  [  560/ 1080]\n",
      "loss: 1.968863  [  640/ 1080]\n",
      "loss: 1.361756  [  720/ 1080]\n",
      "loss: 1.336669  [  800/ 1080]\n",
      "loss: 1.106311  [  880/ 1080]\n",
      "loss: 1.574250  [  960/ 1080]\n",
      "loss: 1.320077  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.905996 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 2.239740  [    0/ 1080]\n",
      "loss: 1.459598  [   80/ 1080]\n",
      "loss: 1.899958  [  160/ 1080]\n",
      "loss: 1.964825  [  240/ 1080]\n",
      "loss: 3.260030  [  320/ 1080]\n",
      "loss: 1.703321  [  400/ 1080]\n",
      "loss: 1.080793  [  480/ 1080]\n",
      "loss: 1.678643  [  560/ 1080]\n",
      "loss: 2.182397  [  640/ 1080]\n",
      "loss: 1.102030  [  720/ 1080]\n",
      "loss: 1.067916  [  800/ 1080]\n",
      "loss: 1.867760  [  880/ 1080]\n",
      "loss: 2.414127  [  960/ 1080]\n",
      "loss: 0.704809  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.760486 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 1.386931  [    0/ 1080]\n",
      "loss: 0.916840  [   80/ 1080]\n",
      "loss: 0.717696  [  160/ 1080]\n",
      "loss: 1.204394  [  240/ 1080]\n",
      "loss: 1.517860  [  320/ 1080]\n",
      "loss: 1.263726  [  400/ 1080]\n",
      "loss: 0.940698  [  480/ 1080]\n",
      "loss: 0.880986  [  560/ 1080]\n",
      "loss: 1.375971  [  640/ 1080]\n",
      "loss: 0.733828  [  720/ 1080]\n",
      "loss: 1.377295  [  800/ 1080]\n",
      "loss: 1.400371  [  880/ 1080]\n",
      "loss: 1.232342  [  960/ 1080]\n",
      "loss: 1.990504  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934375 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 2.081832  [    0/ 1080]\n",
      "loss: 1.232783  [   80/ 1080]\n",
      "loss: 1.110295  [  160/ 1080]\n",
      "loss: 2.407942  [  240/ 1080]\n",
      "loss: 2.212932  [  320/ 1080]\n",
      "loss: 0.658150  [  400/ 1080]\n",
      "loss: 1.439552  [  480/ 1080]\n",
      "loss: 0.762895  [  560/ 1080]\n",
      "loss: 0.670981  [  640/ 1080]\n",
      "loss: 1.151130  [  720/ 1080]\n",
      "loss: 1.525069  [  800/ 1080]\n",
      "loss: 2.856335  [  880/ 1080]\n",
      "loss: 1.379336  [  960/ 1080]\n",
      "loss: 1.507428  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.729914 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 1.408493  [    0/ 1080]\n",
      "loss: 0.787878  [   80/ 1080]\n",
      "loss: 0.682020  [  160/ 1080]\n",
      "loss: 2.142239  [  240/ 1080]\n",
      "loss: 2.330465  [  320/ 1080]\n",
      "loss: 0.606241  [  400/ 1080]\n",
      "loss: 0.950042  [  480/ 1080]\n",
      "loss: 1.534795  [  560/ 1080]\n",
      "loss: 1.206508  [  640/ 1080]\n",
      "loss: 1.063393  [  720/ 1080]\n",
      "loss: 2.014996  [  800/ 1080]\n",
      "loss: 1.574386  [  880/ 1080]\n",
      "loss: 1.819419  [  960/ 1080]\n",
      "loss: 1.585616  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.689347 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.486760  [    0/ 1080]\n",
      "loss: 1.882505  [   80/ 1080]\n",
      "loss: 1.125425  [  160/ 1080]\n",
      "loss: 1.438078  [  240/ 1080]\n",
      "loss: 1.332119  [  320/ 1080]\n",
      "loss: 0.978110  [  400/ 1080]\n",
      "loss: 0.592466  [  480/ 1080]\n",
      "loss: 1.206121  [  560/ 1080]\n",
      "loss: 1.941212  [  640/ 1080]\n",
      "loss: 0.989297  [  720/ 1080]\n",
      "loss: 0.911440  [  800/ 1080]\n",
      "loss: 2.227452  [  880/ 1080]\n",
      "loss: 1.790556  [  960/ 1080]\n",
      "loss: 1.871129  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934375 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.983871  [    0/ 1080]\n",
      "loss: 1.439680  [   80/ 1080]\n",
      "loss: 2.829595  [  160/ 1080]\n",
      "loss: 0.750370  [  240/ 1080]\n",
      "loss: 1.243487  [  320/ 1080]\n",
      "loss: 0.576286  [  400/ 1080]\n",
      "loss: 1.910480  [  480/ 1080]\n",
      "loss: 0.578517  [  560/ 1080]\n",
      "loss: 1.619791  [  640/ 1080]\n",
      "loss: 0.842772  [  720/ 1080]\n",
      "loss: 0.973236  [  800/ 1080]\n",
      "loss: 1.090907  [  880/ 1080]\n",
      "loss: 0.694710  [  960/ 1080]\n",
      "loss: 1.159038  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934375 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 1.735014  [    0/ 1080]\n",
      "loss: 2.177691  [   80/ 1080]\n",
      "loss: 1.387551  [  160/ 1080]\n",
      "loss: 0.685316  [  240/ 1080]\n",
      "loss: 1.762889  [  320/ 1080]\n",
      "loss: 2.326643  [  400/ 1080]\n",
      "loss: 1.270718  [  480/ 1080]\n",
      "loss: 1.069399  [  560/ 1080]\n",
      "loss: 0.990281  [  640/ 1080]\n",
      "loss: 1.249128  [  720/ 1080]\n",
      "loss: 0.893829  [  800/ 1080]\n",
      "loss: 0.896660  [  880/ 1080]\n",
      "loss: 0.808564  [  960/ 1080]\n",
      "loss: 1.163458  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934375 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 1.480235  [    0/ 1080]\n",
      "loss: 1.201707  [   80/ 1080]\n",
      "loss: 1.180671  [  160/ 1080]\n",
      "loss: 0.799900  [  240/ 1080]\n",
      "loss: 1.208235  [  320/ 1080]\n",
      "loss: 1.204166  [  400/ 1080]\n",
      "loss: 1.002270  [  480/ 1080]\n",
      "loss: 1.061314  [  560/ 1080]\n",
      "loss: 1.098119  [  640/ 1080]\n",
      "loss: 2.184368  [  720/ 1080]\n",
      "loss: 2.760732  [  800/ 1080]\n",
      "loss: 3.898841  [  880/ 1080]\n",
      "loss: 1.415696  [  960/ 1080]\n",
      "loss: 1.407609  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.924147 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 2.024066  [    0/ 1080]\n",
      "loss: 1.285539  [   80/ 1080]\n",
      "loss: 1.101821  [  160/ 1080]\n",
      "loss: 1.488098  [  240/ 1080]\n",
      "loss: 1.217582  [  320/ 1080]\n",
      "loss: 1.668982  [  400/ 1080]\n",
      "loss: 1.363304  [  480/ 1080]\n",
      "loss: 0.630635  [  560/ 1080]\n",
      "loss: 0.817376  [  640/ 1080]\n",
      "loss: 0.709410  [  720/ 1080]\n",
      "loss: 1.813030  [  800/ 1080]\n",
      "loss: 0.914540  [  880/ 1080]\n",
      "loss: 1.357747  [  960/ 1080]\n",
      "loss: 1.318200  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.633030 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.967998  [    0/ 1080]\n",
      "loss: 1.747743  [   80/ 1080]\n",
      "loss: 1.486981  [  160/ 1080]\n",
      "loss: 1.772264  [  240/ 1080]\n",
      "loss: 1.190553  [  320/ 1080]\n",
      "loss: 0.850677  [  400/ 1080]\n",
      "loss: 2.845078  [  480/ 1080]\n",
      "loss: 1.500161  [  560/ 1080]\n",
      "loss: 1.267056  [  640/ 1080]\n",
      "loss: 2.178054  [  720/ 1080]\n",
      "loss: 1.652143  [  800/ 1080]\n",
      "loss: 0.863979  [  880/ 1080]\n",
      "loss: 0.934642  [  960/ 1080]\n",
      "loss: 0.464268  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.668058 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 1.098782  [    0/ 1080]\n",
      "loss: 0.974429  [   80/ 1080]\n",
      "loss: 1.604978  [  160/ 1080]\n",
      "loss: 0.600814  [  240/ 1080]\n",
      "loss: 1.741061  [  320/ 1080]\n",
      "loss: 1.215731  [  400/ 1080]\n",
      "loss: 0.699632  [  480/ 1080]\n",
      "loss: 1.144878  [  560/ 1080]\n",
      "loss: 0.900132  [  640/ 1080]\n",
      "loss: 0.940778  [  720/ 1080]\n",
      "loss: 0.725154  [  800/ 1080]\n",
      "loss: 1.265589  [  880/ 1080]\n",
      "loss: 2.099061  [  960/ 1080]\n",
      "loss: 3.885424  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934375 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.720128  [    0/ 1080]\n",
      "loss: 3.394431  [   80/ 1080]\n",
      "loss: 1.072232  [  160/ 1080]\n",
      "loss: 1.729879  [  240/ 1080]\n",
      "loss: 1.106427  [  320/ 1080]\n",
      "loss: 1.878145  [  400/ 1080]\n",
      "loss: 1.274417  [  480/ 1080]\n",
      "loss: 0.727413  [  560/ 1080]\n",
      "loss: 0.919185  [  640/ 1080]\n",
      "loss: 1.807060  [  720/ 1080]\n",
      "loss: 2.348153  [  800/ 1080]\n",
      "loss: 1.272528  [  880/ 1080]\n",
      "loss: 0.757806  [  960/ 1080]\n",
      "loss: 0.832355  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.691245 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 2.575601  [    0/ 1080]\n",
      "loss: 1.312422  [   80/ 1080]\n",
      "loss: 1.631783  [  160/ 1080]\n",
      "loss: 1.427679  [  240/ 1080]\n",
      "loss: 1.466739  [  320/ 1080]\n",
      "loss: 0.944102  [  400/ 1080]\n",
      "loss: 1.681560  [  480/ 1080]\n",
      "loss: 1.555457  [  560/ 1080]\n",
      "loss: 2.185898  [  640/ 1080]\n",
      "loss: 1.654951  [  720/ 1080]\n",
      "loss: 1.190584  [  800/ 1080]\n",
      "loss: 1.566942  [  880/ 1080]\n",
      "loss: 1.482159  [  960/ 1080]\n",
      "loss: 1.486666  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934375 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.596200  [    0/ 1080]\n",
      "loss: 2.068169  [   80/ 1080]\n",
      "loss: 1.275819  [  160/ 1080]\n",
      "loss: 1.016103  [  240/ 1080]\n",
      "loss: 0.810045  [  320/ 1080]\n",
      "loss: 2.591537  [  400/ 1080]\n",
      "loss: 1.204720  [  480/ 1080]\n",
      "loss: 0.934666  [  560/ 1080]\n",
      "loss: 0.923043  [  640/ 1080]\n",
      "loss: 0.659180  [  720/ 1080]\n",
      "loss: 0.611495  [  800/ 1080]\n",
      "loss: 1.315177  [  880/ 1080]\n",
      "loss: 2.705352  [  960/ 1080]\n",
      "loss: 1.656329  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934375 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 1.472342  [    0/ 1080]\n",
      "loss: 1.592124  [   80/ 1080]\n",
      "loss: 0.824052  [  160/ 1080]\n",
      "loss: 1.083365  [  240/ 1080]\n",
      "loss: 1.875488  [  320/ 1080]\n",
      "loss: 0.736203  [  400/ 1080]\n",
      "loss: 0.641451  [  480/ 1080]\n",
      "loss: 2.060718  [  560/ 1080]\n",
      "loss: 1.527028  [  640/ 1080]\n",
      "loss: 1.753441  [  720/ 1080]\n",
      "loss: 1.328267  [  800/ 1080]\n",
      "loss: 0.907937  [  880/ 1080]\n",
      "loss: 1.886391  [  960/ 1080]\n",
      "loss: 1.167490  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.902916 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 1.598043  [    0/ 1080]\n",
      "loss: 0.873464  [   80/ 1080]\n",
      "loss: 0.968142  [  160/ 1080]\n",
      "loss: 0.817362  [  240/ 1080]\n",
      "loss: 2.827137  [  320/ 1080]\n",
      "loss: 0.699594  [  400/ 1080]\n",
      "loss: 1.052247  [  480/ 1080]\n",
      "loss: 0.710360  [  560/ 1080]\n",
      "loss: 1.571588  [  640/ 1080]\n",
      "loss: 0.858484  [  720/ 1080]\n",
      "loss: 1.434090  [  800/ 1080]\n",
      "loss: 1.040261  [  880/ 1080]\n",
      "loss: 1.101202  [  960/ 1080]\n",
      "loss: 1.074396  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.832126 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 1.452904  [    0/ 1080]\n",
      "loss: 0.956398  [   80/ 1080]\n",
      "loss: 1.470145  [  160/ 1080]\n",
      "loss: 1.322746  [  240/ 1080]\n",
      "loss: 1.579913  [  320/ 1080]\n",
      "loss: 2.247278  [  400/ 1080]\n",
      "loss: 0.953720  [  480/ 1080]\n",
      "loss: 1.194437  [  560/ 1080]\n",
      "loss: 0.885768  [  640/ 1080]\n",
      "loss: 1.271534  [  720/ 1080]\n",
      "loss: 1.225370  [  800/ 1080]\n",
      "loss: 1.461455  [  880/ 1080]\n",
      "loss: 1.250934  [  960/ 1080]\n",
      "loss: 1.853395  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.864632 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 1.007693  [    0/ 1080]\n",
      "loss: 1.862556  [   80/ 1080]\n",
      "loss: 1.282742  [  160/ 1080]\n",
      "loss: 0.930947  [  240/ 1080]\n",
      "loss: 0.900845  [  320/ 1080]\n",
      "loss: 1.264717  [  400/ 1080]\n",
      "loss: 1.428043  [  480/ 1080]\n",
      "loss: 0.688377  [  560/ 1080]\n",
      "loss: 1.228250  [  640/ 1080]\n",
      "loss: 0.980812  [  720/ 1080]\n",
      "loss: 2.227760  [  800/ 1080]\n",
      "loss: 2.174122  [  880/ 1080]\n",
      "loss: 0.882074  [  960/ 1080]\n",
      "loss: 1.078269  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.688338 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 1.556872  [    0/ 1080]\n",
      "loss: 1.365224  [   80/ 1080]\n",
      "loss: 2.269088  [  160/ 1080]\n",
      "loss: 0.851819  [  240/ 1080]\n",
      "loss: 0.852153  [  320/ 1080]\n",
      "loss: 1.346521  [  400/ 1080]\n",
      "loss: 2.770885  [  480/ 1080]\n",
      "loss: 2.518670  [  560/ 1080]\n",
      "loss: 1.635827  [  640/ 1080]\n",
      "loss: 1.005374  [  720/ 1080]\n",
      "loss: 0.941769  [  800/ 1080]\n",
      "loss: 0.713301  [  880/ 1080]\n",
      "loss: 2.114304  [  960/ 1080]\n",
      "loss: 0.803250  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934369 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.953115  [    0/ 1080]\n",
      "loss: 1.778036  [   80/ 1080]\n",
      "loss: 1.908737  [  160/ 1080]\n",
      "loss: 1.396616  [  240/ 1080]\n",
      "loss: 1.558453  [  320/ 1080]\n",
      "loss: 1.016309  [  400/ 1080]\n",
      "loss: 1.183619  [  480/ 1080]\n",
      "loss: 1.817592  [  560/ 1080]\n",
      "loss: 1.052347  [  640/ 1080]\n",
      "loss: 1.412279  [  720/ 1080]\n",
      "loss: 1.016990  [  800/ 1080]\n",
      "loss: 1.957622  [  880/ 1080]\n",
      "loss: 1.164348  [  960/ 1080]\n",
      "loss: 0.919915  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.774321 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.973086  [    0/ 1080]\n",
      "loss: 1.751326  [   80/ 1080]\n",
      "loss: 0.894124  [  160/ 1080]\n",
      "loss: 1.330155  [  240/ 1080]\n",
      "loss: 1.391083  [  320/ 1080]\n",
      "loss: 1.287818  [  400/ 1080]\n",
      "loss: 1.123239  [  480/ 1080]\n",
      "loss: 1.433296  [  560/ 1080]\n",
      "loss: 1.345320  [  640/ 1080]\n",
      "loss: 2.127914  [  720/ 1080]\n",
      "loss: 1.143099  [  800/ 1080]\n",
      "loss: 1.475897  [  880/ 1080]\n",
      "loss: 1.239989  [  960/ 1080]\n",
      "loss: 1.962076  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934027 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.809417  [    0/ 1080]\n",
      "loss: 2.824359  [   80/ 1080]\n",
      "loss: 2.386432  [  160/ 1080]\n",
      "loss: 1.257628  [  240/ 1080]\n",
      "loss: 0.607586  [  320/ 1080]\n",
      "loss: 0.849445  [  400/ 1080]\n",
      "loss: 2.265271  [  480/ 1080]\n",
      "loss: 1.066732  [  560/ 1080]\n",
      "loss: 2.008411  [  640/ 1080]\n",
      "loss: 0.775116  [  720/ 1080]\n",
      "loss: 0.815763  [  800/ 1080]\n",
      "loss: 0.747766  [  880/ 1080]\n",
      "loss: 1.121194  [  960/ 1080]\n",
      "loss: 1.089642  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.933504 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 1.167926  [    0/ 1080]\n",
      "loss: 2.588958  [   80/ 1080]\n",
      "loss: 1.678437  [  160/ 1080]\n",
      "loss: 0.902414  [  240/ 1080]\n",
      "loss: 0.652891  [  320/ 1080]\n",
      "loss: 2.086036  [  400/ 1080]\n",
      "loss: 1.053346  [  480/ 1080]\n",
      "loss: 0.689049  [  560/ 1080]\n",
      "loss: 1.813357  [  640/ 1080]\n",
      "loss: 1.547424  [  720/ 1080]\n",
      "loss: 1.535134  [  800/ 1080]\n",
      "loss: 2.241359  [  880/ 1080]\n",
      "loss: 1.230668  [  960/ 1080]\n",
      "loss: 2.097528  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.669028 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.799855  [    0/ 1080]\n",
      "loss: 1.117731  [   80/ 1080]\n",
      "loss: 0.952427  [  160/ 1080]\n",
      "loss: 1.453557  [  240/ 1080]\n",
      "loss: 1.232499  [  320/ 1080]\n",
      "loss: 1.459439  [  400/ 1080]\n",
      "loss: 1.334232  [  480/ 1080]\n",
      "loss: 0.704374  [  560/ 1080]\n",
      "loss: 0.836211  [  640/ 1080]\n",
      "loss: 0.937897  [  720/ 1080]\n",
      "loss: 1.815094  [  800/ 1080]\n",
      "loss: 1.896132  [  880/ 1080]\n",
      "loss: 1.450658  [  960/ 1080]\n",
      "loss: 0.948566  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 1.118865 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 1.400899  [    0/ 1080]\n",
      "loss: 1.241874  [   80/ 1080]\n",
      "loss: 2.217134  [  160/ 1080]\n",
      "loss: 1.119117  [  240/ 1080]\n",
      "loss: 0.916301  [  320/ 1080]\n",
      "loss: 0.645676  [  400/ 1080]\n",
      "loss: 0.807288  [  480/ 1080]\n",
      "loss: 0.696126  [  560/ 1080]\n",
      "loss: 0.893619  [  640/ 1080]\n",
      "loss: 1.634451  [  720/ 1080]\n",
      "loss: 1.470614  [  800/ 1080]\n",
      "loss: 0.788768  [  880/ 1080]\n",
      "loss: 1.483487  [  960/ 1080]\n",
      "loss: 3.347463  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.747080 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 1.045825  [    0/ 1080]\n",
      "loss: 2.109910  [   80/ 1080]\n",
      "loss: 2.723709  [  160/ 1080]\n",
      "loss: 1.577555  [  240/ 1080]\n",
      "loss: 1.146905  [  320/ 1080]\n",
      "loss: 3.145713  [  400/ 1080]\n",
      "loss: 0.883775  [  480/ 1080]\n",
      "loss: 2.860412  [  560/ 1080]\n",
      "loss: 2.394156  [  640/ 1080]\n",
      "loss: 1.801221  [  720/ 1080]\n",
      "loss: 1.462402  [  800/ 1080]\n",
      "loss: 1.203540  [  880/ 1080]\n",
      "loss: 2.591199  [  960/ 1080]\n",
      "loss: 0.741312  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.851590 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 1.333780  [    0/ 1080]\n",
      "loss: 1.214647  [   80/ 1080]\n",
      "loss: 1.272141  [  160/ 1080]\n",
      "loss: 1.566914  [  240/ 1080]\n",
      "loss: 1.342260  [  320/ 1080]\n",
      "loss: 0.990046  [  400/ 1080]\n",
      "loss: 6.158860  [  480/ 1080]\n",
      "loss: 1.087414  [  560/ 1080]\n",
      "loss: 1.587643  [  640/ 1080]\n",
      "loss: 2.113255  [  720/ 1080]\n",
      "loss: 1.079412  [  800/ 1080]\n",
      "loss: 1.225239  [  880/ 1080]\n",
      "loss: 0.846020  [  960/ 1080]\n",
      "loss: 0.869346  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 1.434543 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 1.012398  [    0/ 1080]\n",
      "loss: 1.417835  [   80/ 1080]\n",
      "loss: 2.420721  [  160/ 1080]\n",
      "loss: 0.822569  [  240/ 1080]\n",
      "loss: 1.015885  [  320/ 1080]\n",
      "loss: 0.292681  [  400/ 1080]\n",
      "loss: 2.665770  [  480/ 1080]\n",
      "loss: 1.185970  [  560/ 1080]\n",
      "loss: 1.607870  [  640/ 1080]\n",
      "loss: 2.036096  [  720/ 1080]\n",
      "loss: 1.203085  [  800/ 1080]\n",
      "loss: 1.808838  [  880/ 1080]\n",
      "loss: 0.707097  [  960/ 1080]\n",
      "loss: 0.949487  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 1.209224 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 2.056686  [    0/ 1080]\n",
      "loss: 0.987919  [   80/ 1080]\n",
      "loss: 0.833192  [  160/ 1080]\n",
      "loss: 1.318456  [  240/ 1080]\n",
      "loss: 0.981323  [  320/ 1080]\n",
      "loss: 1.295533  [  400/ 1080]\n",
      "loss: 1.116268  [  480/ 1080]\n",
      "loss: 0.720376  [  560/ 1080]\n",
      "loss: 2.009609  [  640/ 1080]\n",
      "loss: 1.704369  [  720/ 1080]\n",
      "loss: 1.128381  [  800/ 1080]\n",
      "loss: 0.467748  [  880/ 1080]\n",
      "loss: 2.373338  [  960/ 1080]\n",
      "loss: 0.900041  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 1.158134 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.877461  [    0/ 1080]\n",
      "loss: 1.217301  [   80/ 1080]\n",
      "loss: 1.550461  [  160/ 1080]\n",
      "loss: 1.359127  [  240/ 1080]\n",
      "loss: 1.829797  [  320/ 1080]\n",
      "loss: 0.760117  [  400/ 1080]\n",
      "loss: 1.212812  [  480/ 1080]\n",
      "loss: 0.855859  [  560/ 1080]\n",
      "loss: 1.285082  [  640/ 1080]\n",
      "loss: 1.125927  [  720/ 1080]\n",
      "loss: 2.057247  [  800/ 1080]\n",
      "loss: 1.122654  [  880/ 1080]\n",
      "loss: 1.099961  [  960/ 1080]\n",
      "loss: 1.120623  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.914042 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.588260  [    0/ 1080]\n",
      "loss: 1.374720  [   80/ 1080]\n",
      "loss: 1.324932  [  160/ 1080]\n",
      "loss: 0.443973  [  240/ 1080]\n",
      "loss: 1.699270  [  320/ 1080]\n",
      "loss: 1.034916  [  400/ 1080]\n",
      "loss: 0.865439  [  480/ 1080]\n",
      "loss: 1.611012  [  560/ 1080]\n",
      "loss: 1.355757  [  640/ 1080]\n",
      "loss: 1.336945  [  720/ 1080]\n",
      "loss: 0.488567  [  800/ 1080]\n",
      "loss: 1.305628  [  880/ 1080]\n",
      "loss: 0.814834  [  960/ 1080]\n",
      "loss: 0.719284  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.701172 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 1.891865  [    0/ 1080]\n",
      "loss: 0.928331  [   80/ 1080]\n",
      "loss: 1.372072  [  160/ 1080]\n",
      "loss: 1.673743  [  240/ 1080]\n",
      "loss: 0.779997  [  320/ 1080]\n",
      "loss: 1.286841  [  400/ 1080]\n",
      "loss: 1.792704  [  480/ 1080]\n",
      "loss: 2.540570  [  560/ 1080]\n",
      "loss: 0.861369  [  640/ 1080]\n",
      "loss: 1.074005  [  720/ 1080]\n",
      "loss: 0.847224  [  800/ 1080]\n",
      "loss: 2.164599  [  880/ 1080]\n",
      "loss: 0.638835  [  960/ 1080]\n",
      "loss: 1.443526  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.621125 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.829820  [    0/ 1080]\n",
      "loss: 1.194825  [   80/ 1080]\n",
      "loss: 1.524729  [  160/ 1080]\n",
      "loss: 1.370114  [  240/ 1080]\n",
      "loss: 0.799893  [  320/ 1080]\n",
      "loss: 1.097738  [  400/ 1080]\n",
      "loss: 1.177064  [  480/ 1080]\n",
      "loss: 0.635081  [  560/ 1080]\n",
      "loss: 1.263600  [  640/ 1080]\n",
      "loss: 1.314579  [  720/ 1080]\n",
      "loss: 1.073728  [  800/ 1080]\n",
      "loss: 1.904042  [  880/ 1080]\n",
      "loss: 1.272507  [  960/ 1080]\n",
      "loss: 0.881941  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934375 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 1.682102  [    0/ 1080]\n",
      "loss: 0.822976  [   80/ 1080]\n",
      "loss: 1.294651  [  160/ 1080]\n",
      "loss: 1.841072  [  240/ 1080]\n",
      "loss: 1.315716  [  320/ 1080]\n",
      "loss: 1.518377  [  400/ 1080]\n",
      "loss: 0.723476  [  480/ 1080]\n",
      "loss: 1.016917  [  560/ 1080]\n",
      "loss: 1.332755  [  640/ 1080]\n",
      "loss: 1.135412  [  720/ 1080]\n",
      "loss: 1.570312  [  800/ 1080]\n",
      "loss: 1.484549  [  880/ 1080]\n",
      "loss: 0.549440  [  960/ 1080]\n",
      "loss: 0.827136  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.744575 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.821852  [    0/ 1080]\n",
      "loss: 0.897702  [   80/ 1080]\n",
      "loss: 1.224465  [  160/ 1080]\n",
      "loss: 1.956497  [  240/ 1080]\n",
      "loss: 1.378365  [  320/ 1080]\n",
      "loss: 0.792202  [  400/ 1080]\n",
      "loss: 1.213340  [  480/ 1080]\n",
      "loss: 1.285295  [  560/ 1080]\n",
      "loss: 1.113345  [  640/ 1080]\n",
      "loss: 3.815087  [  720/ 1080]\n",
      "loss: 1.660574  [  800/ 1080]\n",
      "loss: 0.912925  [  880/ 1080]\n",
      "loss: 1.445158  [  960/ 1080]\n",
      "loss: 2.350248  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.707388 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.922194  [    0/ 1080]\n",
      "loss: 1.212330  [   80/ 1080]\n",
      "loss: 1.916581  [  160/ 1080]\n",
      "loss: 1.132901  [  240/ 1080]\n",
      "loss: 2.151189  [  320/ 1080]\n",
      "loss: 1.751422  [  400/ 1080]\n",
      "loss: 0.604808  [  480/ 1080]\n",
      "loss: 1.537960  [  560/ 1080]\n",
      "loss: 2.006622  [  640/ 1080]\n",
      "loss: 1.269564  [  720/ 1080]\n",
      "loss: 3.232388  [  800/ 1080]\n",
      "loss: 0.633167  [  880/ 1080]\n",
      "loss: 0.727645  [  960/ 1080]\n",
      "loss: 1.907096  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 1.071395 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 2.100399  [    0/ 1080]\n",
      "loss: 0.565122  [   80/ 1080]\n",
      "loss: 0.956077  [  160/ 1080]\n",
      "loss: 0.889418  [  240/ 1080]\n",
      "loss: 1.015378  [  320/ 1080]\n",
      "loss: 1.619429  [  400/ 1080]\n",
      "loss: 1.413912  [  480/ 1080]\n",
      "loss: 1.264122  [  560/ 1080]\n",
      "loss: 1.280673  [  640/ 1080]\n",
      "loss: 1.015322  [  720/ 1080]\n",
      "loss: 1.075170  [  800/ 1080]\n",
      "loss: 1.756859  [  880/ 1080]\n",
      "loss: 1.283648  [  960/ 1080]\n",
      "loss: 1.719783  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.931201 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 1.213074  [    0/ 1080]\n",
      "loss: 1.118744  [   80/ 1080]\n",
      "loss: 2.086678  [  160/ 1080]\n",
      "loss: 0.796246  [  240/ 1080]\n",
      "loss: 1.339178  [  320/ 1080]\n",
      "loss: 0.738944  [  400/ 1080]\n",
      "loss: 1.367765  [  480/ 1080]\n",
      "loss: 2.043589  [  560/ 1080]\n",
      "loss: 1.255510  [  640/ 1080]\n",
      "loss: 0.776352  [  720/ 1080]\n",
      "loss: 1.126885  [  800/ 1080]\n",
      "loss: 1.529665  [  880/ 1080]\n",
      "loss: 1.059272  [  960/ 1080]\n",
      "loss: 0.969411  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.750694 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 1.016605  [    0/ 1080]\n",
      "loss: 0.776515  [   80/ 1080]\n",
      "loss: 1.046069  [  160/ 1080]\n",
      "loss: 0.978481  [  240/ 1080]\n",
      "loss: 1.193419  [  320/ 1080]\n",
      "loss: 0.857100  [  400/ 1080]\n",
      "loss: 1.005229  [  480/ 1080]\n",
      "loss: 1.284642  [  560/ 1080]\n",
      "loss: 0.792893  [  640/ 1080]\n",
      "loss: 2.098330  [  720/ 1080]\n",
      "loss: 2.134437  [  800/ 1080]\n",
      "loss: 1.498880  [  880/ 1080]\n",
      "loss: 0.966377  [  960/ 1080]\n",
      "loss: 0.970777  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.688695 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.869392  [    0/ 1080]\n",
      "loss: 2.187007  [   80/ 1080]\n",
      "loss: 0.909577  [  160/ 1080]\n",
      "loss: 2.630246  [  240/ 1080]\n",
      "loss: 0.838837  [  320/ 1080]\n",
      "loss: 1.190380  [  400/ 1080]\n",
      "loss: 1.431235  [  480/ 1080]\n",
      "loss: 0.731650  [  560/ 1080]\n",
      "loss: 1.051389  [  640/ 1080]\n",
      "loss: 1.030582  [  720/ 1080]\n",
      "loss: 1.120202  [  800/ 1080]\n",
      "loss: 0.965214  [  880/ 1080]\n",
      "loss: 0.595267  [  960/ 1080]\n",
      "loss: 2.523136  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 1.129908 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 1.537131  [    0/ 1080]\n",
      "loss: 0.803366  [   80/ 1080]\n",
      "loss: 1.103895  [  160/ 1080]\n",
      "loss: 1.037932  [  240/ 1080]\n",
      "loss: 0.613194  [  320/ 1080]\n",
      "loss: 1.649710  [  400/ 1080]\n",
      "loss: 1.683599  [  480/ 1080]\n",
      "loss: 0.553821  [  560/ 1080]\n",
      "loss: 0.889215  [  640/ 1080]\n",
      "loss: 2.290859  [  720/ 1080]\n",
      "loss: 0.846865  [  800/ 1080]\n",
      "loss: 1.280669  [  880/ 1080]\n",
      "loss: 1.514952  [  960/ 1080]\n",
      "loss: 0.723563  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.699611 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 2.089497  [    0/ 1080]\n",
      "loss: 1.181366  [   80/ 1080]\n",
      "loss: 1.054765  [  160/ 1080]\n",
      "loss: 1.689198  [  240/ 1080]\n",
      "loss: 1.471304  [  320/ 1080]\n",
      "loss: 2.807374  [  400/ 1080]\n",
      "loss: 2.358833  [  480/ 1080]\n",
      "loss: 1.133883  [  560/ 1080]\n",
      "loss: 0.884788  [  640/ 1080]\n",
      "loss: 4.009772  [  720/ 1080]\n",
      "loss: 1.619925  [  800/ 1080]\n",
      "loss: 0.603463  [  880/ 1080]\n",
      "loss: 1.106060  [  960/ 1080]\n",
      "loss: 1.255147  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.866302 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 1.561448  [    0/ 1080]\n",
      "loss: 1.976689  [   80/ 1080]\n",
      "loss: 0.967114  [  160/ 1080]\n",
      "loss: 1.344089  [  240/ 1080]\n",
      "loss: 2.451910  [  320/ 1080]\n",
      "loss: 1.169579  [  400/ 1080]\n",
      "loss: 1.141677  [  480/ 1080]\n",
      "loss: 0.771447  [  560/ 1080]\n",
      "loss: 1.834010  [  640/ 1080]\n",
      "loss: 1.346431  [  720/ 1080]\n",
      "loss: 0.944304  [  800/ 1080]\n",
      "loss: 0.676131  [  880/ 1080]\n",
      "loss: 0.756567  [  960/ 1080]\n",
      "loss: 1.248351  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934341 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 2.254670  [    0/ 1080]\n",
      "loss: 1.305843  [   80/ 1080]\n",
      "loss: 1.168959  [  160/ 1080]\n",
      "loss: 1.117316  [  240/ 1080]\n",
      "loss: 1.688147  [  320/ 1080]\n",
      "loss: 1.246977  [  400/ 1080]\n",
      "loss: 0.629465  [  480/ 1080]\n",
      "loss: 1.156588  [  560/ 1080]\n",
      "loss: 0.994418  [  640/ 1080]\n",
      "loss: 0.624311  [  720/ 1080]\n",
      "loss: 1.741219  [  800/ 1080]\n",
      "loss: 1.004196  [  880/ 1080]\n",
      "loss: 1.272478  [  960/ 1080]\n",
      "loss: 2.061207  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.923865 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 1.196983  [    0/ 1080]\n",
      "loss: 0.929925  [   80/ 1080]\n",
      "loss: 1.849547  [  160/ 1080]\n",
      "loss: 1.287793  [  240/ 1080]\n",
      "loss: 1.803150  [  320/ 1080]\n",
      "loss: 2.413444  [  400/ 1080]\n",
      "loss: 0.940986  [  480/ 1080]\n",
      "loss: 3.096663  [  560/ 1080]\n",
      "loss: 1.676005  [  640/ 1080]\n",
      "loss: 0.984954  [  720/ 1080]\n",
      "loss: 0.918020  [  800/ 1080]\n",
      "loss: 1.076251  [  880/ 1080]\n",
      "loss: 2.445941  [  960/ 1080]\n",
      "loss: 1.017677  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934213 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.985494  [    0/ 1080]\n",
      "loss: 0.824169  [   80/ 1080]\n",
      "loss: 1.096948  [  160/ 1080]\n",
      "loss: 1.177983  [  240/ 1080]\n",
      "loss: 0.814031  [  320/ 1080]\n",
      "loss: 0.831480  [  400/ 1080]\n",
      "loss: 0.514418  [  480/ 1080]\n",
      "loss: 2.256014  [  560/ 1080]\n",
      "loss: 0.722349  [  640/ 1080]\n",
      "loss: 2.285892  [  720/ 1080]\n",
      "loss: 1.321483  [  800/ 1080]\n",
      "loss: 1.042361  [  880/ 1080]\n",
      "loss: 0.905096  [  960/ 1080]\n",
      "loss: 1.461806  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.931742 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 1.620956  [    0/ 1080]\n",
      "loss: 1.399980  [   80/ 1080]\n",
      "loss: 1.318099  [  160/ 1080]\n",
      "loss: 0.804878  [  240/ 1080]\n",
      "loss: 1.945854  [  320/ 1080]\n",
      "loss: 1.475420  [  400/ 1080]\n",
      "loss: 0.710902  [  480/ 1080]\n",
      "loss: 1.416001  [  560/ 1080]\n",
      "loss: 1.381914  [  640/ 1080]\n",
      "loss: 1.649367  [  720/ 1080]\n",
      "loss: 1.121946  [  800/ 1080]\n",
      "loss: 0.749229  [  880/ 1080]\n",
      "loss: 1.071476  [  960/ 1080]\n",
      "loss: 0.970174  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.595816 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 2.231327  [    0/ 1080]\n",
      "loss: 0.877154  [   80/ 1080]\n",
      "loss: 0.529369  [  160/ 1080]\n",
      "loss: 2.592903  [  240/ 1080]\n",
      "loss: 1.781846  [  320/ 1080]\n",
      "loss: 0.928311  [  400/ 1080]\n",
      "loss: 1.862316  [  480/ 1080]\n",
      "loss: 2.152644  [  560/ 1080]\n",
      "loss: 0.886965  [  640/ 1080]\n",
      "loss: 1.495376  [  720/ 1080]\n",
      "loss: 1.972812  [  800/ 1080]\n",
      "loss: 1.427776  [  880/ 1080]\n",
      "loss: 1.862075  [  960/ 1080]\n",
      "loss: 1.064101  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.903635 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 1.123706  [    0/ 1080]\n",
      "loss: 1.875483  [   80/ 1080]\n",
      "loss: 1.144629  [  160/ 1080]\n",
      "loss: 1.640623  [  240/ 1080]\n",
      "loss: 1.182289  [  320/ 1080]\n",
      "loss: 0.962537  [  400/ 1080]\n",
      "loss: 1.654376  [  480/ 1080]\n",
      "loss: 0.729299  [  560/ 1080]\n",
      "loss: 1.174650  [  640/ 1080]\n",
      "loss: 1.254711  [  720/ 1080]\n",
      "loss: 1.039781  [  800/ 1080]\n",
      "loss: 1.574968  [  880/ 1080]\n",
      "loss: 1.773679  [  960/ 1080]\n",
      "loss: 1.846500  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.520288 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 2.091304  [    0/ 1080]\n",
      "loss: 0.924508  [   80/ 1080]\n",
      "loss: 1.412205  [  160/ 1080]\n",
      "loss: 1.078055  [  240/ 1080]\n",
      "loss: 0.851767  [  320/ 1080]\n",
      "loss: 1.911498  [  400/ 1080]\n",
      "loss: 0.760224  [  480/ 1080]\n",
      "loss: 0.684604  [  560/ 1080]\n",
      "loss: 1.010586  [  640/ 1080]\n",
      "loss: 2.001429  [  720/ 1080]\n",
      "loss: 0.924904  [  800/ 1080]\n",
      "loss: 1.434750  [  880/ 1080]\n",
      "loss: 1.478544  [  960/ 1080]\n",
      "loss: 1.324398  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.481891 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.481412  [    0/ 1080]\n",
      "loss: 0.671564  [   80/ 1080]\n",
      "loss: 1.241392  [  160/ 1080]\n",
      "loss: 0.882031  [  240/ 1080]\n",
      "loss: 1.095929  [  320/ 1080]\n",
      "loss: 0.914703  [  400/ 1080]\n",
      "loss: 0.974933  [  480/ 1080]\n",
      "loss: 1.515801  [  560/ 1080]\n",
      "loss: 0.684307  [  640/ 1080]\n",
      "loss: 1.220319  [  720/ 1080]\n",
      "loss: 1.080863  [  800/ 1080]\n",
      "loss: 1.867978  [  880/ 1080]\n",
      "loss: 0.991129  [  960/ 1080]\n",
      "loss: 1.169611  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.894293 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 1.713101  [    0/ 1080]\n",
      "loss: 1.929314  [   80/ 1080]\n",
      "loss: 2.282348  [  160/ 1080]\n",
      "loss: 1.666152  [  240/ 1080]\n",
      "loss: 0.844406  [  320/ 1080]\n",
      "loss: 1.191275  [  400/ 1080]\n",
      "loss: 1.804866  [  480/ 1080]\n",
      "loss: 0.936374  [  560/ 1080]\n",
      "loss: 1.317630  [  640/ 1080]\n",
      "loss: 0.897077  [  720/ 1080]\n",
      "loss: 1.295057  [  800/ 1080]\n",
      "loss: 2.166886  [  880/ 1080]\n",
      "loss: 1.799683  [  960/ 1080]\n",
      "loss: 1.150273  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.599092 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 2.643661  [    0/ 1080]\n",
      "loss: 1.208821  [   80/ 1080]\n",
      "loss: 1.214574  [  160/ 1080]\n",
      "loss: 0.929187  [  240/ 1080]\n",
      "loss: 0.832455  [  320/ 1080]\n",
      "loss: 1.862573  [  400/ 1080]\n",
      "loss: 1.153103  [  480/ 1080]\n",
      "loss: 1.476888  [  560/ 1080]\n",
      "loss: 2.351589  [  640/ 1080]\n",
      "loss: 1.012069  [  720/ 1080]\n",
      "loss: 1.566552  [  800/ 1080]\n",
      "loss: 1.739262  [  880/ 1080]\n",
      "loss: 0.973889  [  960/ 1080]\n",
      "loss: 1.929346  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.608103 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 1.582311  [    0/ 1080]\n",
      "loss: 0.641459  [   80/ 1080]\n",
      "loss: 0.829600  [  160/ 1080]\n",
      "loss: 0.805635  [  240/ 1080]\n",
      "loss: 1.247455  [  320/ 1080]\n",
      "loss: 1.496026  [  400/ 1080]\n",
      "loss: 2.232148  [  480/ 1080]\n",
      "loss: 0.580780  [  560/ 1080]\n",
      "loss: 1.257575  [  640/ 1080]\n",
      "loss: 0.773989  [  720/ 1080]\n",
      "loss: 1.470131  [  800/ 1080]\n",
      "loss: 1.276463  [  880/ 1080]\n",
      "loss: 1.976198  [  960/ 1080]\n",
      "loss: 1.642516  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.920566 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.834666  [    0/ 1080]\n",
      "loss: 0.808245  [   80/ 1080]\n",
      "loss: 2.682227  [  160/ 1080]\n",
      "loss: 0.962693  [  240/ 1080]\n",
      "loss: 0.764755  [  320/ 1080]\n",
      "loss: 1.178016  [  400/ 1080]\n",
      "loss: 1.123014  [  480/ 1080]\n",
      "loss: 1.429702  [  560/ 1080]\n",
      "loss: 1.005144  [  640/ 1080]\n",
      "loss: 1.763371  [  720/ 1080]\n",
      "loss: 1.512411  [  800/ 1080]\n",
      "loss: 2.591088  [  880/ 1080]\n",
      "loss: 1.010603  [  960/ 1080]\n",
      "loss: 0.764317  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 1.274453 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.967046  [    0/ 1080]\n",
      "loss: 1.555759  [   80/ 1080]\n",
      "loss: 1.729716  [  160/ 1080]\n",
      "loss: 1.188816  [  240/ 1080]\n",
      "loss: 2.341531  [  320/ 1080]\n",
      "loss: 0.888044  [  400/ 1080]\n",
      "loss: 1.806467  [  480/ 1080]\n",
      "loss: 1.982959  [  560/ 1080]\n",
      "loss: 1.533625  [  640/ 1080]\n",
      "loss: 0.998634  [  720/ 1080]\n",
      "loss: 1.643414  [  800/ 1080]\n",
      "loss: 2.465441  [  880/ 1080]\n",
      "loss: 1.327131  [  960/ 1080]\n",
      "loss: 1.629911  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.837213 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 1.571745  [    0/ 1080]\n",
      "loss: 1.423587  [   80/ 1080]\n",
      "loss: 1.479286  [  160/ 1080]\n",
      "loss: 0.691852  [  240/ 1080]\n",
      "loss: 1.067068  [  320/ 1080]\n",
      "loss: 0.842964  [  400/ 1080]\n",
      "loss: 1.872358  [  480/ 1080]\n",
      "loss: 1.028696  [  560/ 1080]\n",
      "loss: 1.235444  [  640/ 1080]\n",
      "loss: 1.997819  [  720/ 1080]\n",
      "loss: 2.661535  [  800/ 1080]\n",
      "loss: 0.970415  [  880/ 1080]\n",
      "loss: 0.959349  [  960/ 1080]\n",
      "loss: 1.577022  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934353 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.667259  [    0/ 1080]\n",
      "loss: 0.890491  [   80/ 1080]\n",
      "loss: 0.974526  [  160/ 1080]\n",
      "loss: 0.814013  [  240/ 1080]\n",
      "loss: 1.372810  [  320/ 1080]\n",
      "loss: 1.541073  [  400/ 1080]\n",
      "loss: 1.278539  [  480/ 1080]\n",
      "loss: 0.904469  [  560/ 1080]\n",
      "loss: 1.560285  [  640/ 1080]\n",
      "loss: 1.685638  [  720/ 1080]\n",
      "loss: 0.749836  [  800/ 1080]\n",
      "loss: 1.144412  [  880/ 1080]\n",
      "loss: 1.704535  [  960/ 1080]\n",
      "loss: 1.540196  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.930486 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 1.293326  [    0/ 1080]\n",
      "loss: 0.891595  [   80/ 1080]\n",
      "loss: 1.347510  [  160/ 1080]\n",
      "loss: 1.269851  [  240/ 1080]\n",
      "loss: 1.341915  [  320/ 1080]\n",
      "loss: 1.386502  [  400/ 1080]\n",
      "loss: 1.636850  [  480/ 1080]\n",
      "loss: 0.991753  [  560/ 1080]\n",
      "loss: 1.332952  [  640/ 1080]\n",
      "loss: 1.164129  [  720/ 1080]\n",
      "loss: 2.281976  [  800/ 1080]\n",
      "loss: 1.776097  [  880/ 1080]\n",
      "loss: 1.415634  [  960/ 1080]\n",
      "loss: 2.200763  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934375 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 1.889134  [    0/ 1080]\n",
      "loss: 0.961815  [   80/ 1080]\n",
      "loss: 1.248627  [  160/ 1080]\n",
      "loss: 0.678196  [  240/ 1080]\n",
      "loss: 1.067196  [  320/ 1080]\n",
      "loss: 2.621209  [  400/ 1080]\n",
      "loss: 0.859233  [  480/ 1080]\n",
      "loss: 0.874784  [  560/ 1080]\n",
      "loss: 0.780371  [  640/ 1080]\n",
      "loss: 3.496118  [  720/ 1080]\n",
      "loss: 0.704440  [  800/ 1080]\n",
      "loss: 0.963038  [  880/ 1080]\n",
      "loss: 1.213211  [  960/ 1080]\n",
      "loss: 1.549415  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.742159 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 1.082320  [    0/ 1080]\n",
      "loss: 0.810050  [   80/ 1080]\n",
      "loss: 0.854495  [  160/ 1080]\n",
      "loss: 0.743909  [  240/ 1080]\n",
      "loss: 0.946218  [  320/ 1080]\n",
      "loss: 1.363731  [  400/ 1080]\n",
      "loss: 1.527408  [  480/ 1080]\n",
      "loss: 0.878840  [  560/ 1080]\n",
      "loss: 1.122444  [  640/ 1080]\n",
      "loss: 1.839009  [  720/ 1080]\n",
      "loss: 0.931788  [  800/ 1080]\n",
      "loss: 0.617040  [  880/ 1080]\n",
      "loss: 1.921504  [  960/ 1080]\n",
      "loss: 0.949442  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934375 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.812474  [    0/ 1080]\n",
      "loss: 2.372666  [   80/ 1080]\n",
      "loss: 1.026401  [  160/ 1080]\n",
      "loss: 3.092340  [  240/ 1080]\n",
      "loss: 1.503332  [  320/ 1080]\n",
      "loss: 1.659124  [  400/ 1080]\n",
      "loss: 1.246994  [  480/ 1080]\n",
      "loss: 1.390179  [  560/ 1080]\n",
      "loss: 0.445075  [  640/ 1080]\n",
      "loss: 1.338645  [  720/ 1080]\n",
      "loss: 1.098541  [  800/ 1080]\n",
      "loss: 2.340581  [  880/ 1080]\n",
      "loss: 1.465040  [  960/ 1080]\n",
      "loss: 0.989433  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.810491 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.983191  [    0/ 1080]\n",
      "loss: 1.109994  [   80/ 1080]\n",
      "loss: 1.637029  [  160/ 1080]\n",
      "loss: 1.178687  [  240/ 1080]\n",
      "loss: 1.491292  [  320/ 1080]\n",
      "loss: 1.690449  [  400/ 1080]\n",
      "loss: 1.067625  [  480/ 1080]\n",
      "loss: 0.990133  [  560/ 1080]\n",
      "loss: 1.415165  [  640/ 1080]\n",
      "loss: 0.872739  [  720/ 1080]\n",
      "loss: 1.481491  [  800/ 1080]\n",
      "loss: 1.582255  [  880/ 1080]\n",
      "loss: 1.161280  [  960/ 1080]\n",
      "loss: 2.029221  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.582768 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 1.862138  [    0/ 1080]\n",
      "loss: 1.334122  [   80/ 1080]\n",
      "loss: 2.012899  [  160/ 1080]\n",
      "loss: 1.034500  [  240/ 1080]\n",
      "loss: 0.669735  [  320/ 1080]\n",
      "loss: 1.376374  [  400/ 1080]\n",
      "loss: 1.422105  [  480/ 1080]\n",
      "loss: 1.920625  [  560/ 1080]\n",
      "loss: 0.932242  [  640/ 1080]\n",
      "loss: 1.828859  [  720/ 1080]\n",
      "loss: 0.626281  [  800/ 1080]\n",
      "loss: 1.259265  [  880/ 1080]\n",
      "loss: 1.281380  [  960/ 1080]\n",
      "loss: 1.060208  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934375 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.784454  [    0/ 1080]\n",
      "loss: 1.432406  [   80/ 1080]\n",
      "loss: 0.954612  [  160/ 1080]\n",
      "loss: 1.268479  [  240/ 1080]\n",
      "loss: 1.883397  [  320/ 1080]\n",
      "loss: 1.316390  [  400/ 1080]\n",
      "loss: 1.670418  [  480/ 1080]\n",
      "loss: 0.718454  [  560/ 1080]\n",
      "loss: 2.259056  [  640/ 1080]\n",
      "loss: 1.567676  [  720/ 1080]\n",
      "loss: 1.285636  [  800/ 1080]\n",
      "loss: 1.643091  [  880/ 1080]\n",
      "loss: 1.290648  [  960/ 1080]\n",
      "loss: 1.034832  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.696222 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 1.519941  [    0/ 1080]\n",
      "loss: 2.021415  [   80/ 1080]\n",
      "loss: 1.697887  [  160/ 1080]\n",
      "loss: 1.757561  [  240/ 1080]\n",
      "loss: 1.055503  [  320/ 1080]\n",
      "loss: 1.599991  [  400/ 1080]\n",
      "loss: 1.127692  [  480/ 1080]\n",
      "loss: 1.384666  [  560/ 1080]\n",
      "loss: 1.256815  [  640/ 1080]\n",
      "loss: 0.892906  [  720/ 1080]\n",
      "loss: 1.132005  [  800/ 1080]\n",
      "loss: 1.775868  [  880/ 1080]\n",
      "loss: 1.167025  [  960/ 1080]\n",
      "loss: 1.601437  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.661909 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 1.110109  [    0/ 1080]\n",
      "loss: 1.052152  [   80/ 1080]\n",
      "loss: 1.023328  [  160/ 1080]\n",
      "loss: 1.436080  [  240/ 1080]\n",
      "loss: 1.697889  [  320/ 1080]\n",
      "loss: 0.532241  [  400/ 1080]\n",
      "loss: 1.184738  [  480/ 1080]\n",
      "loss: 1.757561  [  560/ 1080]\n",
      "loss: 2.703348  [  640/ 1080]\n",
      "loss: 2.958510  [  720/ 1080]\n",
      "loss: 1.588010  [  800/ 1080]\n",
      "loss: 2.056454  [  880/ 1080]\n",
      "loss: 0.595465  [  960/ 1080]\n",
      "loss: 1.082557  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.661719 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 1.454857  [    0/ 1080]\n",
      "loss: 1.239196  [   80/ 1080]\n",
      "loss: 1.118737  [  160/ 1080]\n",
      "loss: 1.705114  [  240/ 1080]\n",
      "loss: 1.980839  [  320/ 1080]\n",
      "loss: 1.254631  [  400/ 1080]\n",
      "loss: 1.509679  [  480/ 1080]\n",
      "loss: 1.632710  [  560/ 1080]\n",
      "loss: 1.177852  [  640/ 1080]\n",
      "loss: 1.743217  [  720/ 1080]\n",
      "loss: 1.495641  [  800/ 1080]\n",
      "loss: 0.926588  [  880/ 1080]\n",
      "loss: 0.977471  [  960/ 1080]\n",
      "loss: 1.175550  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.931622 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 1.987252  [    0/ 1080]\n",
      "loss: 1.477006  [   80/ 1080]\n",
      "loss: 0.923153  [  160/ 1080]\n",
      "loss: 0.632003  [  240/ 1080]\n",
      "loss: 1.357595  [  320/ 1080]\n",
      "loss: 2.713459  [  400/ 1080]\n",
      "loss: 1.466508  [  480/ 1080]\n",
      "loss: 1.734053  [  560/ 1080]\n",
      "loss: 1.448031  [  640/ 1080]\n",
      "loss: 0.908240  [  720/ 1080]\n",
      "loss: 1.969676  [  800/ 1080]\n",
      "loss: 1.493322  [  880/ 1080]\n",
      "loss: 0.608339  [  960/ 1080]\n",
      "loss: 0.898064  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.776175 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 1.124756  [    0/ 1080]\n",
      "loss: 1.061357  [   80/ 1080]\n",
      "loss: 1.643524  [  160/ 1080]\n",
      "loss: 2.039439  [  240/ 1080]\n",
      "loss: 1.269946  [  320/ 1080]\n",
      "loss: 0.952115  [  400/ 1080]\n",
      "loss: 1.337969  [  480/ 1080]\n",
      "loss: 2.379288  [  560/ 1080]\n",
      "loss: 1.575516  [  640/ 1080]\n",
      "loss: 2.025754  [  720/ 1080]\n",
      "loss: 1.080781  [  800/ 1080]\n",
      "loss: 2.897974  [  880/ 1080]\n",
      "loss: 1.265604  [  960/ 1080]\n",
      "loss: 0.803785  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 1.035390 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 1.174692  [    0/ 1080]\n",
      "loss: 0.906342  [   80/ 1080]\n",
      "loss: 1.726293  [  160/ 1080]\n",
      "loss: 2.009873  [  240/ 1080]\n",
      "loss: 1.293207  [  320/ 1080]\n",
      "loss: 1.344725  [  400/ 1080]\n",
      "loss: 0.929657  [  480/ 1080]\n",
      "loss: 1.155599  [  560/ 1080]\n",
      "loss: 1.675901  [  640/ 1080]\n",
      "loss: 1.676189  [  720/ 1080]\n",
      "loss: 0.756788  [  800/ 1080]\n",
      "loss: 1.730758  [  880/ 1080]\n",
      "loss: 0.882951  [  960/ 1080]\n",
      "loss: 1.638070  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.739114 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 2.809531  [    0/ 1080]\n",
      "loss: 1.760921  [   80/ 1080]\n",
      "loss: 0.618968  [  160/ 1080]\n",
      "loss: 1.001243  [  240/ 1080]\n",
      "loss: 0.526285  [  320/ 1080]\n",
      "loss: 1.243500  [  400/ 1080]\n",
      "loss: 1.372784  [  480/ 1080]\n",
      "loss: 1.187365  [  560/ 1080]\n",
      "loss: 0.961181  [  640/ 1080]\n",
      "loss: 2.800185  [  720/ 1080]\n",
      "loss: 1.141446  [  800/ 1080]\n",
      "loss: 0.820079  [  880/ 1080]\n",
      "loss: 1.263742  [  960/ 1080]\n",
      "loss: 1.689270  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934367 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 1.654244  [    0/ 1080]\n",
      "loss: 1.189906  [   80/ 1080]\n",
      "loss: 1.913625  [  160/ 1080]\n",
      "loss: 1.161856  [  240/ 1080]\n",
      "loss: 1.101536  [  320/ 1080]\n",
      "loss: 1.375527  [  400/ 1080]\n",
      "loss: 0.878864  [  480/ 1080]\n",
      "loss: 0.838766  [  560/ 1080]\n",
      "loss: 1.370976  [  640/ 1080]\n",
      "loss: 1.757915  [  720/ 1080]\n",
      "loss: 0.916769  [  800/ 1080]\n",
      "loss: 1.020290  [  880/ 1080]\n",
      "loss: 0.660534  [  960/ 1080]\n",
      "loss: 1.126818  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.934375 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.999015  [    0/ 1080]\n",
      "loss: 1.465139  [   80/ 1080]\n",
      "loss: 1.193103  [  160/ 1080]\n",
      "loss: 1.814730  [  240/ 1080]\n",
      "loss: 1.308560  [  320/ 1080]\n",
      "loss: 0.515280  [  400/ 1080]\n",
      "loss: 0.962283  [  480/ 1080]\n",
      "loss: 2.105636  [  560/ 1080]\n",
      "loss: 0.550561  [  640/ 1080]\n",
      "loss: 1.301435  [  720/ 1080]\n",
      "loss: 1.480861  [  800/ 1080]\n",
      "loss: 0.772545  [  880/ 1080]\n",
      "loss: 1.188767  [  960/ 1080]\n",
      "loss: 1.481851  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.624265 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 1.216877  [    0/ 1080]\n",
      "loss: 1.146778  [   80/ 1080]\n",
      "loss: 1.291273  [  160/ 1080]\n",
      "loss: 0.622273  [  240/ 1080]\n",
      "loss: 2.148502  [  320/ 1080]\n",
      "loss: 1.619049  [  400/ 1080]\n",
      "loss: 1.135752  [  480/ 1080]\n",
      "loss: 1.590582  [  560/ 1080]\n",
      "loss: 2.406162  [  640/ 1080]\n",
      "loss: 0.991765  [  720/ 1080]\n",
      "loss: 1.205909  [  800/ 1080]\n",
      "loss: 1.824843  [  880/ 1080]\n",
      "loss: 1.009553  [  960/ 1080]\n",
      "loss: 1.974884  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.680499 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.617507  [    0/ 1080]\n",
      "loss: 1.008987  [   80/ 1080]\n",
      "loss: 0.938407  [  160/ 1080]\n",
      "loss: 1.080509  [  240/ 1080]\n",
      "loss: 1.649852  [  320/ 1080]\n",
      "loss: 1.562598  [  400/ 1080]\n",
      "loss: 2.301327  [  480/ 1080]\n",
      "loss: 0.901135  [  560/ 1080]\n",
      "loss: 1.338277  [  640/ 1080]\n",
      "loss: 1.121234  [  720/ 1080]\n",
      "loss: 0.567770  [  800/ 1080]\n",
      "loss: 0.746018  [  880/ 1080]\n",
      "loss: 1.397778  [  960/ 1080]\n",
      "loss: 0.707805  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.868608 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 1.070359  [    0/ 1080]\n",
      "loss: 2.536795  [   80/ 1080]\n",
      "loss: 1.006077  [  160/ 1080]\n",
      "loss: 1.034891  [  240/ 1080]\n",
      "loss: 1.512100  [  320/ 1080]\n",
      "loss: 0.546324  [  400/ 1080]\n",
      "loss: 0.648706  [  480/ 1080]\n",
      "loss: 1.249723  [  560/ 1080]\n",
      "loss: 2.411841  [  640/ 1080]\n",
      "loss: 2.008379  [  720/ 1080]\n",
      "loss: 0.524426  [  800/ 1080]\n",
      "loss: 1.975582  [  880/ 1080]\n",
      "loss: 0.957646  [  960/ 1080]\n",
      "loss: 0.635812  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.603536 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 1.089869  [    0/ 1080]\n",
      "loss: 0.834735  [   80/ 1080]\n",
      "loss: 1.151789  [  160/ 1080]\n",
      "loss: 2.560007  [  240/ 1080]\n",
      "loss: 1.153848  [  320/ 1080]\n",
      "loss: 0.868422  [  400/ 1080]\n",
      "loss: 1.336745  [  480/ 1080]\n",
      "loss: 0.653563  [  560/ 1080]\n",
      "loss: 0.422040  [  640/ 1080]\n",
      "loss: 0.983503  [  720/ 1080]\n",
      "loss: 0.933082  [  800/ 1080]\n",
      "loss: 1.360984  [  880/ 1080]\n",
      "loss: 1.593224  [  960/ 1080]\n",
      "loss: 1.107072  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.862284 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 1.013273  [    0/ 1080]\n",
      "loss: 0.699628  [   80/ 1080]\n",
      "loss: 0.629530  [  160/ 1080]\n",
      "loss: 1.958108  [  240/ 1080]\n",
      "loss: 1.024356  [  320/ 1080]\n",
      "loss: 1.453334  [  400/ 1080]\n",
      "loss: 0.938118  [  480/ 1080]\n",
      "loss: 0.608760  [  560/ 1080]\n",
      "loss: 1.567956  [  640/ 1080]\n",
      "loss: 1.064661  [  720/ 1080]\n",
      "loss: 0.807588  [  800/ 1080]\n",
      "loss: 2.138032  [  880/ 1080]\n",
      "loss: 0.884087  [  960/ 1080]\n",
      "loss: 1.244682  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 1.365163 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 1.155069  [    0/ 1080]\n",
      "loss: 1.293160  [   80/ 1080]\n",
      "loss: 1.178127  [  160/ 1080]\n",
      "loss: 0.572464  [  240/ 1080]\n",
      "loss: 0.862154  [  320/ 1080]\n",
      "loss: 0.623666  [  400/ 1080]\n",
      "loss: 1.699856  [  480/ 1080]\n",
      "loss: 1.377097  [  560/ 1080]\n",
      "loss: 1.242049  [  640/ 1080]\n",
      "loss: 0.667565  [  720/ 1080]\n",
      "loss: 0.738378  [  800/ 1080]\n",
      "loss: 1.150504  [  880/ 1080]\n",
      "loss: 1.446221  [  960/ 1080]\n",
      "loss: 1.851633  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 0.890289 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.702374  [    0/ 1080]\n",
      "loss: 1.322622  [   80/ 1080]\n",
      "loss: 0.857837  [  160/ 1080]\n",
      "loss: 1.782737  [  240/ 1080]\n",
      "loss: 2.029332  [  320/ 1080]\n",
      "loss: 1.086992  [  400/ 1080]\n",
      "loss: 1.134627  [  480/ 1080]\n",
      "loss: 0.834483  [  560/ 1080]\n",
      "loss: 2.766130  [  640/ 1080]\n",
      "loss: 1.133916  [  720/ 1080]\n",
      "loss: 0.935388  [  800/ 1080]\n",
      "loss: 1.241925  [  880/ 1080]\n",
      "loss: 1.032625  [  960/ 1080]\n",
      "loss: 0.728332  [ 1040/ 1080]\n",
      "Test Error: \n",
      " Avg loss: 1.359915 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01, amsgrad=True) # 0.0001\n",
    "epochs = 150\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 24.00 GiB total capacity; 20.52 GiB already allocated; 0 bytes free; 20.91 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\MichaelSNelson\\OneDrive - UW-Madison\\GitHub_clones\\zebrafish_embryo_segmentation\\Regression scratch model.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=1'>2</a>\u001b[0m n\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=3'>4</a>\u001b[0m train_images, train_ages\u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(test_dataloader))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=4'>5</a>\u001b[0m agesout \u001b[39m=\u001b[39m model(train_images\u001b[39m.\u001b[39;49mcuda())\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFeature batch shape: \u001b[39m\u001b[39m{\u001b[39;00mtrain_images\u001b[39m.\u001b[39msize()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=6'>7</a>\u001b[0m img \u001b[39m=\u001b[39m train_images[n]\u001b[39m.\u001b[39msqueeze()\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\MichaelSNelson\\OneDrive - UW-Madison\\GitHub_clones\\zebrafish_embryo_segmentation\\Regression scratch model.ipynb Cell 27\u001b[0m in \u001b[0;36mUNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=10'>11</a>\u001b[0m encoding_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=11'>12</a>\u001b[0m \u001b[39m#Note [::-1] flips the order of the encoding channels so they start with 1024\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=12'>13</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(encoding_features[::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m][\u001b[39m0\u001b[39;49m], encoding_features[::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m][\u001b[39m1\u001b[39;49m:])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=13'>14</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead(out)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=14'>15</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretain_dim:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\MichaelSNelson\\OneDrive - UW-Madison\\GitHub_clones\\zebrafish_embryo_segmentation\\Regression scratch model.ipynb Cell 27\u001b[0m in \u001b[0;36mDecoder.forward\u001b[1;34m(self, x, encoder_features)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=10'>11</a>\u001b[0m     adjusted_encoder_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrop(encoder_features[i], x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=11'>12</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([x, adjusted_encoder_features], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=12'>13</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdec_blocks[i](x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=13'>14</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\MichaelSNelson\\OneDrive - UW-Madison\\GitHub_clones\\zebrafish_embryo_segmentation\\Regression scratch model.ipynb Cell 27\u001b[0m in \u001b[0;36mBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=11'>12</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=12'>13</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm2(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm1(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x))))))\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:168\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    163\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[0;32m    169\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[0;32m    170\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    171\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[0;32m    172\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[0;32m    173\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    175\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m    176\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[0;32m    177\u001b[0m     bn_training,\n\u001b[0;32m    178\u001b[0m     exponential_average_factor,\n\u001b[0;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[0;32m    180\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\functional.py:2421\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2418\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[0;32m   2419\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[1;32m-> 2421\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[0;32m   2422\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[0;32m   2423\u001b[0m )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 24.00 GiB total capacity; 20.52 GiB already allocated; 0 bytes free; 20.91 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "#pick an image to view\n",
    "n=4\n",
    "\n",
    "train_images, train_ages= next(iter(test_dataloader))\n",
    "agesout = model(train_images.cuda())\n",
    "print(f\"Feature batch shape: {train_images.size()}\")\n",
    "img = train_images[n].squeeze()\n",
    "\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(agesout[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentSave = \"FirstTestAgePredict_manual_unet.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model, currentSave)\n",
    "\n",
    "# model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "# model_scripted.save(currentSave) # Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = torch.load(currentSave)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "conv2d() received an invalid combination of arguments - got (str, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!str!, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!str!, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\MichaelSNelson\\OneDrive - UW-Madison\\GitHub_clones\\zebrafish_embryo_segmentation\\Regression scratch model.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000029?line=0'>1</a>\u001b[0m out \u001b[39m=\u001b[39m model2(img_test_paths[\u001b[39m2\u001b[39;49m])\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\MichaelSNelson\\OneDrive - UW-Madison\\GitHub_clones\\zebrafish_embryo_segmentation\\Regression scratch model.ipynb Cell 26\u001b[0m in \u001b[0;36mUNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000029?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000029?line=10'>11</a>\u001b[0m     encoding_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000029?line=11'>12</a>\u001b[0m     \u001b[39m#Note [::-1] flips the order of the encoding channels so they start with 1024\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000029?line=12'>13</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(encoding_features[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m], encoding_features[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m:])\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\MichaelSNelson\\OneDrive - UW-Madison\\GitHub_clones\\zebrafish_embryo_segmentation\\Regression scratch model.ipynb Cell 26\u001b[0m in \u001b[0;36mEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000029?line=8'>9</a>\u001b[0m features \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000029?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m block \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menc_blocks:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000029?line=10'>11</a>\u001b[0m     x\u001b[39m=\u001b[39mblock(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000029?line=11'>12</a>\u001b[0m     features\u001b[39m.\u001b[39mappend(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000029?line=12'>13</a>\u001b[0m     x\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(x)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\MichaelSNelson\\OneDrive - UW-Madison\\GitHub_clones\\zebrafish_embryo_segmentation\\Regression scratch model.ipynb Cell 26\u001b[0m in \u001b[0;36mBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000029?line=11'>12</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000029?line=12'>13</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x))))))\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\conv.py:447\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 447\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\conv.py:443\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    441\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    442\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 443\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    444\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mTypeError\u001b[0m: conv2d() received an invalid combination of arguments - got (str, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!str!, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!str!, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n"
     ]
    }
   ],
   "source": [
    "out = model2(img_test_paths[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('fastai2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "f69c838de7ce47136ebe027dd64b911371851962ad08f8b0aa77da2666fa0521"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
