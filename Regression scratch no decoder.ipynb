{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load an image and pass it to a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, img_as_float, img_as_ubyte\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "#import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "#significant input from https://amaarora.github.io/2020/09/13/unet.html and Pytorch documentation examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes = 15\n",
    "#def name_to_hrs (r): return float(round(float(os.path.basename(r)[0:-4].split(\"_\")[1][1:])*(minutes/60)+5,2))\n",
    "def name_to_hrs (r): return float(round(float(os.path.basename(r)[0:-4].split(\"_\")[1][1:])*(minutes/60)+5,2))\n",
    "time = name_to_hrs('D:/pytorch/data/2D_FishAge_pytorch/images/S000_t000028_V000_R0005_X000_Y000_C02_I0_D0_P00344_MP.tif')\n",
    "device = 'cuda'\n",
    "img_train_paths = glob('D:/pytorch/data/2D_FishAge_pytorch/images/*.tif')\n",
    "img_test_paths = glob('D:/pytorch/data/2D_FishAge_pytorch/testimages/*.tif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time\n",
    "#model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=1, out_channels=1, init_features=8, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for a standard unet block that takes in in_ch and results in out_ch\n",
    "# 3x3 conv and no padding currently\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3,1,1)\n",
    "        self.norm1 = nn.BatchNorm2d(out_ch, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.relu  =nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3,1,1)\n",
    "        self.norm2 = nn.BatchNorm2d(out_ch, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.norm2(self.conv2(self.relu(self.norm1(self.conv1(x))))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, chs = (1,64,128,256,512,1024)):\n",
    "        super().__init__()\n",
    "        self.enc_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)])\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = []\n",
    "        for block in self.enc_blocks:\n",
    "            x=block(x)\n",
    "            features.append(x)\n",
    "            x=self.pool(x)\n",
    "        return features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Decoder(nn.Module):\n",
    "#     def __init__(self, chs=(1024,512,256,128,64)):\n",
    "#         super().__init__()\n",
    "#         self.chs = chs\n",
    "#         self.upconvs = nn.ModuleList([nn.ConvTranspose2d(chs[i], chs[i+1], 2,2) for i in range(len(chs)-1)])\n",
    "#         self.dec_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)])\n",
    "\n",
    "#     def forward(self, x, encoder_features):\n",
    "#         for i in range(len(self.chs)-1):\n",
    "#             x=self.upconvs[i](x)\n",
    "#             adjusted_encoder_features = self.crop(encoder_features[i], x)\n",
    "#             x = torch.cat([x, adjusted_encoder_features], dim=1)\n",
    "#             x = self.dec_blocks[i](x)\n",
    "#         return x\n",
    "    \n",
    "#     def crop(self, adjusted_encoder_features, x):\n",
    "#         _,_,H,W = x.shape\n",
    "#         adjusted_encoder_features = transforms.CenterCrop([H,W])(adjusted_encoder_features)\n",
    "#         return adjusted_encoder_features\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_classes is the number of channels in the output. Not really desired as we want a mask\n",
    "#change output to layer with highest value?\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, encoding_channels= (1,64,128,256,512,1024), decoding_channels = (1024, 512, 256, 128, 64), num_class = 512, retain_dim=False):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(encoding_channels)\n",
    "        #self.decoder = Decoder(decoding_channels)\n",
    "        #self.head = nn.Conv2d(decoding_channels[-1], num_class, 1)\n",
    "        self.retain_dim = retain_dim\n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        #Note [::-1] flips the order of the encoding channels so they start with 1024\n",
    "        #out = self.decoder(encoding_features[::-1][0], encoding_features[::-1][1:])\n",
    "        #out = self.head(out)\n",
    "        if self.retain_dim:\n",
    "            out = F.interpolate(out, (512,512))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out how to use one layer of pretrained weights https://github.com/avijit9/forces/blob/master/model.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flatten(start_dim=1, end_dim=-1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): UNet(\n",
       "    (encoder): Encoder(\n",
       "      (enc_blocks): ModuleList(\n",
       "        (0): Block(\n",
       "          (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): Block(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): Block(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): Block(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): Block(\n",
       "          (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (1): regression_net(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "    (norm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (drop1): Dropout(p=0.25, inplace=False)\n",
       "    (linear1): Linear(in_features=512, out_features=256, bias=False)\n",
       "    (relu): ReLU()\n",
       "    (norm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (drop2): Dropout(p=0.25, inplace=False)\n",
       "    (fc): Linear(in_features=256, out_features=1, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class regression_net(nn.Module):\n",
    "    def __init__(self, y_range = (4.9, 24)):\n",
    "        super(regression_net, self).__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.norm1 = nn.BatchNorm1d(512, eps=1e-5, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.drop1 = nn.Dropout(p=0.25, inplace=False)\n",
    "        self.linear1 = nn.Linear(in_features = 512, out_features = 256, bias = False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.norm2 = nn.BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.drop2 = nn.Dropout(p=0.25, inplace=False)\n",
    "        self.fc = nn.Linear(256, 1, bias=False)\n",
    "        self.y_range = y_range\n",
    "    def forward(self, x):\n",
    "        x = self.fc(self.drop2(self.norm2(self.relu(self.linear1(self.drop1(self.norm1(self.flat(self.pool(x)))))))))\n",
    "        #print(x.shape)\n",
    "        #Final age should be between 5 and 24 hours\n",
    "   \n",
    "\n",
    "        return (torch.sigmoid(x)*(self.y_range[1]-self.y_range[0])+self.y_range[0])\n",
    "# self.pool = nn.AdaptiveAvgPool2d((32,32))\n",
    "model = UNet()\n",
    "regnet = regression_net()\n",
    "model = nn.Sequential(model, regnet)\n",
    "##########\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.to(device)\n",
    "# input = torch.from_numpy( img )[None, None, :].float()\n",
    "# input = input.to('cuda')\n",
    "# output = model(input)\n",
    "# output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "#def loss_fn (output, target): return 0.5*(output- target)**2\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2) # 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_transforms = transforms.Compose([\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Resize((512,512)),\n",
    "    transforms.Normalize(mean = 0.5, std=0.5),\n",
    "    #transforms.ColorJitter(contrast = 0.2),\n",
    "    transforms.RandomVerticalFlip(0.3),\n",
    "    transforms.RandomHorizontalFlip(0.3),\n",
    "    transforms.RandomApply([transforms.RandomRotation((90,90))], p=0.5)\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageValuePair(Dataset):\n",
    "    def __init__(self, img_paths, transforms=None):\n",
    "        self.img_paths = img_paths\n",
    "        \n",
    "        if transforms is not None:\n",
    "            self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = img_as_float(io.imread(self.img_paths[idx]))\n",
    "        age = torch.tensor(name_to_hrs(self.img_paths[idx]))\n",
    "        img = self.transforms(img)\n",
    "        return img, age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y = y.view(-1,1)\n",
    "        #print(X[200:250, 200:250])\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(pred)\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            N = len(X)\n",
    "            #print(batchLen)\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X) # N x 1 x H x W\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            #print(f\"Actual:{y:>8f} \\n Pred: {pred:>8f} \\n\")\n",
    "    test_loss /= size\n",
    "    print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train = ImageValuePair(img_train_paths,  transforms=pair_transforms)\n",
    "train_dataloader = DataLoader(image_train, batch_size=8, shuffle=True)\n",
    "image_test= ImageValuePair(img_test_paths, transforms=pair_transforms)\n",
    "test_dataloader = DataLoader(image_test, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_images = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #pick an image to view\n",
    "# n=1\n",
    "\n",
    "# train_images, train_ages= next(iter(test_dataloader))\n",
    "# agesout = model(train_images.cuda())\n",
    "# print(f\"Feature batch shape: {train_images.size()}\")\n",
    "# img = train_images[n].squeeze()\n",
    "\n",
    "# plt.imshow(img, cmap=\"gray\")\n",
    "# plt.show()\n",
    "# print(agesout[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\MichaelSNelson\\OneDrive - UW-Madison\\GitHub_clones\\zebrafish_embryo_segmentation\\Regression scratch no decoder.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20no%20decoder.ipynb#ch0000021?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20no%20decoder.ipynb#ch0000021?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20no%20decoder.ipynb#ch0000021?line=4'>5</a>\u001b[0m     train(train_dataloader, model, loss_fn, optimizer)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20no%20decoder.ipynb#ch0000021?line=5'>6</a>\u001b[0m     test(test_dataloader, model, loss_fn)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20no%20decoder.ipynb#ch0000021?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\MichaelSNelson\\OneDrive - UW-Madison\\GitHub_clones\\zebrafish_embryo_segmentation\\Regression scratch no decoder.ipynb Cell 22\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20no%20decoder.ipynb#ch0000021?line=6'>7</a>\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20no%20decoder.ipynb#ch0000021?line=7'>8</a>\u001b[0m \u001b[39m#print(X[200:250, 200:250])\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20no%20decoder.ipynb#ch0000021?line=8'>9</a>\u001b[0m \u001b[39m# Compute prediction error\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20no%20decoder.ipynb#ch0000021?line=9'>10</a>\u001b[0m pred \u001b[39m=\u001b[39m model(X)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20no%20decoder.ipynb#ch0000021?line=11'>12</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(pred, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20no%20decoder.ipynb#ch0000021?line=12'>13</a>\u001b[0m \u001b[39m# Backpropagation\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\MichaelSNelson\\OneDrive - UW-Madison\\GitHub_clones\\zebrafish_embryo_segmentation\\Regression scratch no decoder.ipynb Cell 22\u001b[0m in \u001b[0;36mregression_net.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20no%20decoder.ipynb#ch0000021?line=13'>14</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20no%20decoder.ipynb#ch0000021?line=14'>15</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear1(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop1(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflat(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpool(x)))))))))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20no%20decoder.ipynb#ch0000021?line=15'>16</a>\u001b[0m     \u001b[39m#print(x.shape)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20no%20decoder.ipynb#ch0000021?line=16'>17</a>\u001b[0m     \u001b[39m#Final age should be between 5 and 24 hours\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20no%20decoder.ipynb#ch0000021?line=19'>20</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m (torch\u001b[39m.\u001b[39msigmoid(x)\u001b[39m*\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_range[\u001b[39m1\u001b[39m]\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_range[\u001b[39m0\u001b[39m])\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_range[\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\pooling.py:1179\u001b[0m, in \u001b[0;36mAdaptiveAvgPool2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> 1179\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49madaptive_avg_pool2d(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_size)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\functional.py:1240\u001b[0m, in \u001b[0;36madaptive_avg_pool2d\u001b[1;34m(input, output_size)\u001b[0m\n\u001b[0;32m   1238\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39minput\u001b[39m):\n\u001b[0;32m   1239\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(adaptive_avg_pool2d, (\u001b[39minput\u001b[39m,), \u001b[39minput\u001b[39m, output_size)\n\u001b[1;32m-> 1240\u001b[0m _output_size \u001b[39m=\u001b[39m _list_with_default(output_size, \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msize())\n\u001b[0;32m   1241\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39madaptive_avg_pool2d(\u001b[39minput\u001b[39m, _output_size)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01, amsgrad=True) # 0.0001\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 24.00 GiB total capacity; 20.52 GiB already allocated; 0 bytes free; 20.91 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\MichaelSNelson\\OneDrive - UW-Madison\\GitHub_clones\\zebrafish_embryo_segmentation\\Regression scratch model.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=1'>2</a>\u001b[0m n\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=3'>4</a>\u001b[0m train_images, train_ages\u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(test_dataloader))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=4'>5</a>\u001b[0m agesout \u001b[39m=\u001b[39m model(train_images\u001b[39m.\u001b[39;49mcuda())\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFeature batch shape: \u001b[39m\u001b[39m{\u001b[39;00mtrain_images\u001b[39m.\u001b[39msize()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=6'>7</a>\u001b[0m img \u001b[39m=\u001b[39m train_images[n]\u001b[39m.\u001b[39msqueeze()\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\MichaelSNelson\\OneDrive - UW-Madison\\GitHub_clones\\zebrafish_embryo_segmentation\\Regression scratch model.ipynb Cell 27\u001b[0m in \u001b[0;36mUNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=10'>11</a>\u001b[0m encoding_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=11'>12</a>\u001b[0m \u001b[39m#Note [::-1] flips the order of the encoding channels so they start with 1024\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=12'>13</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(encoding_features[::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m][\u001b[39m0\u001b[39;49m], encoding_features[::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m][\u001b[39m1\u001b[39;49m:])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=13'>14</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead(out)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=14'>15</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretain_dim:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\MichaelSNelson\\OneDrive - UW-Madison\\GitHub_clones\\zebrafish_embryo_segmentation\\Regression scratch model.ipynb Cell 27\u001b[0m in \u001b[0;36mDecoder.forward\u001b[1;34m(self, x, encoder_features)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=10'>11</a>\u001b[0m     adjusted_encoder_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrop(encoder_features[i], x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=11'>12</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([x, adjusted_encoder_features], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=12'>13</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdec_blocks[i](x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=13'>14</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\MichaelSNelson\\OneDrive - UW-Madison\\GitHub_clones\\zebrafish_embryo_segmentation\\Regression scratch model.ipynb Cell 27\u001b[0m in \u001b[0;36mBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=11'>12</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000020?line=12'>13</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm2(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm1(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x))))))\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:168\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    163\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[0;32m    169\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[0;32m    170\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    171\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[0;32m    172\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[0;32m    173\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    175\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m    176\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[0;32m    177\u001b[0m     bn_training,\n\u001b[0;32m    178\u001b[0m     exponential_average_factor,\n\u001b[0;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[0;32m    180\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\functional.py:2421\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2418\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[0;32m   2419\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[1;32m-> 2421\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[0;32m   2422\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[0;32m   2423\u001b[0m )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 512.00 MiB (GPU 0; 24.00 GiB total capacity; 20.52 GiB already allocated; 0 bytes free; 20.91 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "#pick an image to view\n",
    "n=4\n",
    "\n",
    "train_images, train_ages= next(iter(test_dataloader))\n",
    "agesout = model(train_images.cuda())\n",
    "print(f\"Feature batch shape: {train_images.size()}\")\n",
    "img = train_images[n].squeeze()\n",
    "\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(agesout[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentSave = \"FirstTestAgePredict_manual_unet.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model, currentSave)\n",
    "\n",
    "# model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "# model_scripted.save(currentSave) # Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = torch.load(currentSave)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "conv2d() received an invalid combination of arguments - got (str, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!str!, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!str!, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\MichaelSNelson\\OneDrive - UW-Madison\\GitHub_clones\\zebrafish_embryo_segmentation\\Regression scratch model.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000029?line=0'>1</a>\u001b[0m out \u001b[39m=\u001b[39m model2(img_test_paths[\u001b[39m2\u001b[39;49m])\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\MichaelSNelson\\OneDrive - UW-Madison\\GitHub_clones\\zebrafish_embryo_segmentation\\Regression scratch model.ipynb Cell 26\u001b[0m in \u001b[0;36mUNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000029?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000029?line=10'>11</a>\u001b[0m     encoding_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000029?line=11'>12</a>\u001b[0m     \u001b[39m#Note [::-1] flips the order of the encoding channels so they start with 1024\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000029?line=12'>13</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(encoding_features[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m], encoding_features[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m:])\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\MichaelSNelson\\OneDrive - UW-Madison\\GitHub_clones\\zebrafish_embryo_segmentation\\Regression scratch model.ipynb Cell 26\u001b[0m in \u001b[0;36mEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000029?line=8'>9</a>\u001b[0m features \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000029?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m block \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menc_blocks:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000029?line=10'>11</a>\u001b[0m     x\u001b[39m=\u001b[39mblock(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000029?line=11'>12</a>\u001b[0m     features\u001b[39m.\u001b[39mappend(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000029?line=12'>13</a>\u001b[0m     x\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(x)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\MichaelSNelson\\OneDrive - UW-Madison\\GitHub_clones\\zebrafish_embryo_segmentation\\Regression scratch model.ipynb Cell 26\u001b[0m in \u001b[0;36mBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000029?line=11'>12</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/MichaelSNelson/OneDrive%20-%20UW-Madison/GitHub_clones/zebrafish_embryo_segmentation/Regression%20scratch%20model.ipynb#ch0000029?line=12'>13</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x))))))\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\conv.py:447\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 447\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\fastai2\\lib\\site-packages\\torch\\nn\\modules\\conv.py:443\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    441\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    442\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 443\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    444\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mTypeError\u001b[0m: conv2d() received an invalid combination of arguments - got (str, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!str!, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!str!, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n"
     ]
    }
   ],
   "source": [
    "out = model2(img_test_paths[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('fastai2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "f69c838de7ce47136ebe027dd64b911371851962ad08f8b0aa77da2666fa0521"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
